{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa720897",
   "metadata": {},
   "source": [
    "# Monitoring Environmental Waste Utilization Scores\n",
    "# A guide for generating EWU-Dashboards\n",
    "**Sarah Schmidt & David Laner**  \n",
    "*January 2023*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c01f25a",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6fcfd",
   "metadata": {},
   "source": [
    "### 1.1 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09e7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import brightway2 as bw\n",
    "import premise\n",
    "from mycolorpy import colorlist as mcp\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cd9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with MS Excel column indices (A, B, ..., Z, AA, AB, ...)\n",
    "# will be used for preparing calculations in MS Excel\n",
    "alphabet = list(string.ascii_uppercase)\n",
    "excel_cols=[]\n",
    "\n",
    "for i in range(100):\n",
    "    n=0\n",
    "    j=i\n",
    "    while j-len(alphabet)>=0:\n",
    "        j=j-len(alphabet)\n",
    "        n=n+1\n",
    "    if n>0:\n",
    "        col=alphabet[n-1]+alphabet[j]\n",
    "    else:\n",
    "        col=alphabet[j]\n",
    "    excel_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499e5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factors={'kg':1,\n",
    "                    't':1e3,\n",
    "                    'kt':1e6,\n",
    "                    'g':1e-3,\n",
    "                    'Mg':1e3,\n",
    "                    'Gg':1e6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a828067",
   "metadata": {},
   "source": [
    "### 1.2 Gather case study-specific information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b49f5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read various case study specific information from input data file (ExcelTool_GeneratorInput_Template.xlsx)\n",
    "general_info=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='GeneralInformation', index_col=0)\n",
    "general_info=general_info[general_info.columns[0]].to_dict()\n",
    "\n",
    "Pathway_codes=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')\n",
    "Pathway_codes=Pathway_codes[Pathway_codes['Pathway tag'].notnull()]['Activity code'].to_list()\n",
    "Pathway_names=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')\n",
    "Pathway_names=Pathway_names[Pathway_names['Pathway tag'].notnull()]['Pathway tag'].to_list()\n",
    "\n",
    "WasteGen_code=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')\n",
    "WasteGen_code=WasteGen_code[WasteGen_code['Waste generation'].notnull()]['Activity code'].iloc[0]\n",
    "\n",
    "act_codes=[WasteGen_code,*Pathway_codes]\n",
    "act_names=[general_info['Acronym'],*Pathway_names]\n",
    "\n",
    "# foreground system\n",
    "activity_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')\n",
    "foreground_system_codes=activity_df[activity_df['Foreground'].notnull()]['Activity code'].to_list()\n",
    "\n",
    "# number of foreground system scenarios\n",
    "n_scenarios=general_info['Maximum number of foreground system scenarios']\n",
    "\n",
    "# materials for calculation of the environmental impact of materials\n",
    "material_names=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='EnvironmentalValue')\n",
    "material_names=material_names['Material Name'].to_list()\n",
    "material_codes=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='EnvironmentalValue')\n",
    "material_codes=material_codes['Material Code'].to_list()\n",
    "activity_material_dict={}\n",
    "for i in activity_df.index:\n",
    "    if pd.isnull(activity_df.loc[i,'Material tag'])==False:\n",
    "        activity_material_dict[activity_df.loc[i,'Activity code']]=activity_df.loc[i,'Material tag']\n",
    "        \n",
    "waste_utilization_codes=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')\n",
    "waste_utilization_codes=waste_utilization_codes[pd.isnull(waste_utilization_codes['Waste utilization'])==False]['Activity code'].to_list()\n",
    "\n",
    "# activity tags for contribution analysis\n",
    "activity_tags=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')\n",
    "activity_tags=activity_tags['Activity tag'].to_list()\n",
    "activity_tags=[tag for tag in activity_tags if pd.isnull(tag)==False]\n",
    "activity_tags=list(set(activity_tags))\n",
    "activity_tags.append('Others')\n",
    "\n",
    "# waste quantity in kg\n",
    "WQ_kg=general_info['Waste quantity']*conversion_factors[general_info['Unit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c1fc4b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity code</th>\n",
       "      <th>Activity name</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity tag</th>\n",
       "      <th>Material tag</th>\n",
       "      <th>Pathway tag</th>\n",
       "      <th>Waste generation</th>\n",
       "      <th>Waste utilization</th>\n",
       "      <th>Foreground</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avoidedCO2</td>\n",
       "      <td>avoided emissions, CO2</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>Substitution of Fuels in Cement Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dehoust et al. 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cans-Substitution</td>\n",
       "      <td>substitution of aluminium cans</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>Avoided Production of Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>Substitution of Fuels in Cement Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>Dehoust et al. 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CemKiln-FuelSubst-PE</td>\n",
       "      <td>substitution of fuels in cement kilns, polyeth...</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>Substitution of Fuels in Cement Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>Dehoust et al. 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CemKiln-FuelSubst-PET</td>\n",
       "      <td>substitution of fuels in cement kilns, polyeth...</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>Substitution of Fuels in Cement Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>Dehoust et al. 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Mix-Mech-Rec_export</td>\n",
       "      <td>recycling of mixed polymers</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>Mechanical Recycling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>Van Eygen et al. (2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>ChemRecMP_export</td>\n",
       "      <td>thermochemical recycling, MP</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>Chemical Recycling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>Civancik-Uslu et al. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>electricity-Substitution_export</td>\n",
       "      <td>substitution of electricity</td>\n",
       "      <td>kilowatt hour</td>\n",
       "      <td>GLO</td>\n",
       "      <td>Avoided Production of Heat and Electricity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>heat_mix_export</td>\n",
       "      <td>market for heat, mix, export countries</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>GLO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>heat-Substitution_export</td>\n",
       "      <td>substitution of heat</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>GLO</td>\n",
       "      <td>Avoided Production of Heat and Electricity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Activity code  \\\n",
       "0                         avoidedCO2   \n",
       "1                  Cans-Substitution   \n",
       "2               CemKiln-FuelSubst-MP   \n",
       "3               CemKiln-FuelSubst-PE   \n",
       "4              CemKiln-FuelSubst-PET   \n",
       "..                               ...   \n",
       "185              Mix-Mech-Rec_export   \n",
       "186                 ChemRecMP_export   \n",
       "187  electricity-Substitution_export   \n",
       "188                  heat_mix_export   \n",
       "189         heat-Substitution_export   \n",
       "\n",
       "                                         Activity name           Unit  \\\n",
       "0                               avoided emissions, CO2       kilogram   \n",
       "1                       substitution of aluminium cans       kilogram   \n",
       "2    substitution of fuels in cement kilns, mixed p...       kilogram   \n",
       "3    substitution of fuels in cement kilns, polyeth...       kilogram   \n",
       "4    substitution of fuels in cement kilns, polyeth...       kilogram   \n",
       "..                                                 ...            ...   \n",
       "185                        recycling of mixed polymers       kilogram   \n",
       "186                       thermochemical recycling, MP       kilogram   \n",
       "187                        substitution of electricity  kilowatt hour   \n",
       "188             market for heat, mix, export countries      megajoule   \n",
       "189                               substitution of heat      megajoule   \n",
       "\n",
       "    Location                                Activity tag Material tag  \\\n",
       "0        GLO    Substitution of Fuels in Cement Industry          NaN   \n",
       "1        GLO             Avoided Production of Materials          NaN   \n",
       "2         DE    Substitution of Fuels in Cement Industry          NaN   \n",
       "3         DE    Substitution of Fuels in Cement Industry          NaN   \n",
       "4         DE    Substitution of Fuels in Cement Industry          NaN   \n",
       "..       ...                                         ...          ...   \n",
       "185      GLO                        Mechanical Recycling          NaN   \n",
       "186      GLO                          Chemical Recycling          NaN   \n",
       "187      GLO  Avoided Production of Heat and Electricity          NaN   \n",
       "188      GLO                                         NaN          NaN   \n",
       "189      GLO  Avoided Production of Heat and Electricity          NaN   \n",
       "\n",
       "    Pathway tag Waste generation Waste utilization Foreground  \\\n",
       "0           NaN              NaN                 x        NaN   \n",
       "1           NaN              NaN                 x        NaN   \n",
       "2           NaN              NaN                 x          x   \n",
       "3           NaN              NaN                 x          x   \n",
       "4           NaN              NaN                 x          x   \n",
       "..          ...              ...               ...        ...   \n",
       "185         NaN              NaN               NaN          x   \n",
       "186         NaN              NaN               NaN          x   \n",
       "187         NaN              NaN                 x        NaN   \n",
       "188         NaN              NaN               NaN        NaN   \n",
       "189         NaN              NaN                 x        NaN   \n",
       "\n",
       "                     Reference  \n",
       "0          Dehoust et al. 2016  \n",
       "1                            -  \n",
       "2          Dehoust et al. 2016  \n",
       "3          Dehoust et al. 2016  \n",
       "4          Dehoust et al. 2016  \n",
       "..                         ...  \n",
       "185    Van Eygen et al. (2018)  \n",
       "186  Civancik-Uslu et al. 2021  \n",
       "187                          -  \n",
       "188                          -  \n",
       "189                          -  \n",
       "\n",
       "[190 rows x 11 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e5341955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DRS-Reuse-Bottle': 'PET',\n",
       " 'DRS-Reuse-Cap-HDPE': 'PE-HD',\n",
       " 'DRS-Reuse-Cap-PP': 'PP',\n",
       " 'DRS-SingleUse-Bottle': 'PET',\n",
       " 'DRS-SingleUse-Cap-HDPE': 'PE-HD',\n",
       " 'DRS-SingleUse-Cap-PP': 'PP',\n",
       " 'littering_EPS': 'EPS',\n",
       " 'littering_Films': 'Films',\n",
       " 'littering_HDPE': 'PE-HD',\n",
       " 'littering_PET': 'PET',\n",
       " 'littering_PP': 'PP',\n",
       " 'littering_PS': 'PS',\n",
       " 'LWP-Waste-EPS': 'EPS',\n",
       " 'LWP-Waste-Films': 'Films',\n",
       " 'LWP-Waste-HDPE': 'PE-HD',\n",
       " 'LWP-Waste-PET': 'PET',\n",
       " 'LWP-Waste-PP': 'PP',\n",
       " 'LWP-Waste-PS': 'PS',\n",
       " 'Residual-Waste-EPS-Inc': 'EPS',\n",
       " 'Residual-Waste-EPS-MBT': 'EPS',\n",
       " 'Residual-Waste-Films-Inc': 'Films',\n",
       " 'Residual-Waste-Films-MBT': 'Films',\n",
       " 'Residual-Waste-HDPE-Inc': 'PE-HD',\n",
       " 'Residual-Waste-HDPE-MBT': 'PE-HD',\n",
       " 'Residual-Waste-PET-Inc': 'PET',\n",
       " 'Residual-Waste-PET-MBT': 'PET',\n",
       " 'Residual-Waste-PP-Inc': 'PP',\n",
       " 'Residual-Waste-PP-MBT': 'PP',\n",
       " 'Residual-Waste-PS-Inc': 'PS',\n",
       " 'Residual-Waste-PS-MBT': 'PS',\n",
       " 'littering_HDPE_export': 'PE-HD',\n",
       " 'littering_PP_export': 'PP',\n",
       " 'littering_PET_export': 'PET',\n",
       " 'littering_PS_export': 'PS',\n",
       " 'littering_Films_export': 'Films'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d97a094",
   "metadata": {},
   "source": [
    "### 1.3 Setup and import of databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862eae0",
   "metadata": {},
   "source": [
    "#### 1.3.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89ae321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new project or open an existing project\n",
    "bw.projects.set_current(general_info['Project name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9394db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating default biosphere\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying strategy: normalize_units\n",
      "Applying strategy: drop_unspecified_subcategories\n",
      "Applying strategy: ensure_categories_are_tuples\n",
      "Applied 3 strategies in 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 01/16/2023 15:59:58\n",
      "  Finished: 01/16/2023 15:59:58\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 6.90\n",
      "  Memory %: 1.66\n",
      "Created database: biosphere3\n",
      "Creating default LCIA methods\n",
      "\n",
      "Applying strategy: normalize_units\n",
      "Applying strategy: set_biosphere_type\n",
      "Applying strategy: fix_ecoinvent_38_lcia_implementation\n",
      "Applying strategy: drop_unspecified_subcategories\n",
      "Applying strategy: link_iterable_by_fields\n",
      "Applied 5 strategies in 1.77 seconds\n",
      "Wrote 975 LCIA methods with 254388 characterization factors\n",
      "Creating core data migrations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creates the database \"biosphere 3\"\n",
    "bw.bw2setup() \n",
    "biosphere = bw.Database(\"biosphere3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7650e6f",
   "metadata": {},
   "source": [
    "#### 1.3.2 Ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f9518e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting XML data from 19128 datasets\n",
      "Extracted 19128 datasets in 79.63 seconds\n",
      "Applying strategy: normalize_units\n",
      "Applying strategy: update_ecoinvent_locations\n",
      "Applying strategy: remove_zero_amount_coproducts\n",
      "Applying strategy: remove_zero_amount_inputs_with_no_activity\n",
      "Applying strategy: remove_unnamed_parameters\n",
      "Applying strategy: es2_assign_only_product_with_amount_as_reference_product\n",
      "Applying strategy: assign_single_product_as_activity\n",
      "Applying strategy: create_composite_code\n",
      "Applying strategy: drop_unspecified_subcategories\n",
      "Applying strategy: fix_ecoinvent_flows_pre35\n",
      "Applying strategy: drop_temporary_outdated_biosphere_flows\n",
      "Applying strategy: link_biosphere_by_flow_uuid\n",
      "Applying strategy: link_internal_technosphere_by_composite_code\n",
      "Applying strategy: delete_exchanges_missing_activity\n",
      "Applying strategy: delete_ghost_exchanges\n",
      "Applying strategy: remove_uncertainty_from_negative_loss_exchanges\n",
      "Applying strategy: fix_unreasonably_high_lognormal_uncertainties\n",
      "Applying strategy: set_lognormal_loc_value\n",
      "Applying strategy: convert_activity_parameters_to_list\n",
      "Applying strategy: add_cpc_classification_from_single_reference_product\n",
      "Applying strategy: delete_none_synonyms\n",
      "Applied 21 strategies in 8.74 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19128 datasets\n",
      "621719 exchanges\n",
      "0 unlinked exchanges\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 01/16/2023 16:03:19\n",
      "  Finished: 01/16/2023 16:04:24\n",
      "  Total time elapsed: 00:01:05\n",
      "  CPU %: 23.30\n",
      "  Memory %: 21.99\n",
      "Created database: ecoinvent 3.7.1_cutoff_ecoSpold02_default\n"
     ]
    }
   ],
   "source": [
    "# import of the ecoinvent database\n",
    "db_default_name=general_info['Database name']+'_default'\n",
    "if db_default_name in bw.databases:\n",
    "    print(\"Database has already been imported.\")\n",
    "    eidb_default = bw.Database(db_default_name)\n",
    "else:\n",
    "    # mind that the ecoinvent file must be unzipped; then: path to the datasets subfolder\n",
    "    fpeidbcut = r\"{}\".format(general_info['Database file path'])\n",
    "    # the \"r\" makes sure that the path is read as a string - especially useful when you have spaces in your string\n",
    "    eidbcut = bw.SingleOutputEcospold2Importer(fpeidbcut, general_info['Database name']+'_default')\n",
    "    eidbcut\n",
    "    eidbcut.apply_strategies()\n",
    "    eidbcut.statistics()\n",
    "    eidb_default=eidbcut.write_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb2e671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 01/16/2023 16:08:20\n",
      "  Finished: 01/16/2023 16:09:24\n",
      "  Total time elapsed: 00:01:04\n",
      "  CPU %: 20.00\n",
      "  Memory %: 55.29\n"
     ]
    }
   ],
   "source": [
    "# copy of the unmodified version of the ecoinvent database\n",
    "if general_info['Database name'] in bw.databases:\n",
    "    print(\"Database has already been imported.\")\n",
    "else:\n",
    "    eidb_default.copy(general_info['Database name'])\n",
    "eidb = bw.Database(general_info['Database name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f31b8",
   "metadata": {},
   "source": [
    "#### 1.3.3 Prospective Databases (premise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e9dfbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather information which prospective scenarios shall be created\n",
    "premise_scenarios=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='ProspectiveScenarios', \n",
    "                                skiprows=3, nrows=8)\n",
    "premise_update=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='ProspectiveScenarios', \n",
    "                                index_col=0, skiprows=15, nrows=9, usecols='A:B')\n",
    "premise_update=premise_update[premise_update['Update']=='yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3068a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read encryption key \n",
    "# (to be requested from the premise library maintainers if you want ot use default scenarios included in `premise`)\n",
    "encryption_key=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='ProspectiveScenarios', \n",
    "                         usecols = \"B\", header = 0, nrows=0).columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07fd0d28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise v.(1, 3, 0)\n",
      "+------------------------------------------------------------------+\n",
      "| Warning                                                          |\n",
      "+------------------------------------------------------------------+\n",
      "| Because some of the scenarios can yield LCI databases            |\n",
      "| containing net negative emission technologies (NET),             |\n",
      "| it is advised to account for biogenic CO2 flows when calculating |\n",
      "| Global Warming potential indicators.                             |\n",
      "| `premise_gwp` provides characterization factors for such flows.  |\n",
      "| It also provides factors for hydrogen emissions to air.          |\n",
      "|                                                                  |\n",
      "| Within your bw2 project:                                         |\n",
      "| from premise_gwp import add_premise_gwp                          |\n",
      "| add_premise_gwp()                                                |\n",
      "+------------------------------------------------------------------+\n",
      "+--------------------------------+----------------------------------+\n",
      "| Utils functions                | Description                      |\n",
      "+--------------------------------+----------------------------------+\n",
      "| clear_cache()                  | Clears the cache folder. Useful  |\n",
      "|                                | when updating `premise`or        |\n",
      "|                                | encountering issues with         |\n",
      "|                                | inventories.                     |\n",
      "+--------------------------------+----------------------------------+\n",
      "| get_regions_definition(model)  | Retrieves the list of countries  |\n",
      "|                                | for each region of the model.    |\n",
      "+--------------------------------+----------------------------------+\n",
      "| ndb.NewDatabase(...)           | Generates a summary of the most  |\n",
      "| ndb.generate_scenario_report() | important scenarios' variables.  |\n",
      "+--------------------------------+----------------------------------+\n",
      "Keep uncertainty data?\n",
      "NewDatabase(..., keep_uncertainty_data=True)\n",
      "\n",
      "Hide these messages?\n",
      "NewDatabase(..., quiet=True)\n",
      "\n",
      "//////////////////// EXTRACTING SOURCE DATABASE ////////////////////\n",
      "Cannot find cached database. Will create one now for next time...\n",
      "Getting activity data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 19128/19128 [00:00<00:00, 87866.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding exchange data to activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 621719/621719 [00:51<00:00, 12112.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling out exchange data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 19128/19128 [00:03<00:00, 5282.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set missing location of datasets to global scope.\n",
      "Set missing location of production exchanges to scope of dataset.\n",
      "Correct missing location of technosphere exchanges.\n",
      "Correct missing flow categories for biosphere exchanges\n",
      "Remove empty exchanges.\n",
      "Remove uncertainty data.\n",
      "Done!\n",
      "\n",
      "////////////////// IMPORTING DEFAULT INVENTORIES ///////////////////\n",
      "Cannot find cached inventories. Will create them now for next time...\n",
      "Importing default inventories...\n",
      "\n",
      "Done!\n",
      "\n",
      "Data cached. It is advised to restart your workflow at this point.\n",
      "This allows premise to use the cached data instead, which results in\n",
      "a faster workflow.\n",
      "Done!\n",
      "\n",
      "/////////////////////// EXTRACTING IAM DATA ////////////////////////\n",
      "Done!\n",
      "\n",
      "////////////////////////// TWO-WHEELERS ////////////////////////////\n",
      "Extracted 39 worksheets in 1.60 seconds\n",
      "Done!\n",
      "\n",
      "///////////////////////// PASSENGER CARS ///////////////////////////\n",
      "Extracted 1 worksheets in 6.46 seconds\n",
      "Done!\n",
      "\n",
      "////////////////// MEDIUM AND HEAVY DUTY TRUCKS ////////////////////\n",
      "Extracted 1 worksheets in 12.40 seconds\n",
      "Create fleet average vehicles...\n",
      "Done!\n",
      "\n",
      "////////////////////////////// BUSES ///////////////////////////////\n",
      "Extracted 1 worksheets in 1.53 seconds\n",
      "The following datasets to import already exist in the source database. They will not be imported\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "|                     Name                    |       Reference product        | Location |      File      |\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "|        assembly operation, for lorry        | assembly operation, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|               cabin, for lorry              |        cabin, for lorry        |   RER    | lci-buses.xlsx |\n",
      "|          exhaust system, for lorry          |   exhaust system, for lorry    |   RER    | lci-buses.xlsx |\n",
      "|     frame, blanks and saddle, for lorry     | frame, blanks and saddle, for  |   RER    | lci-buses.xlsx |\n",
      "|        fuel tank, for diesel vehicle        |           fuel tank            |   RER    | lci-buses.xlsx |\n",
      "|              gearbox, for lorry             |       gearbox, for lorry       |   RER    | lci-buses.xlsx |\n",
      "|    internal combustion engine, for lorry    | internal combustion engine, fo |   RER    | lci-buses.xlsx |\n",
      "|         lead acid battery, for lorry        |  lead acid battery, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|     other components, for electric lorry    | other components, for electric |   RER    | lci-buses.xlsx |\n",
      "| other components, for hybrid electric lorry | other components, for hybrid e |   RER    | lci-buses.xlsx |\n",
      "|         power electronics, for lorry        |  power electronics, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|             retarder, for lorry             |      retarder, for lorry       |   RER    | lci-buses.xlsx |\n",
      "|            suspension, for lorry            |     suspension, for lorry      |   RER    | lci-buses.xlsx |\n",
      "|         tires and wheels, for lorry         |  tires and wheels, for lorry   |   RER    | lci-buses.xlsx |\n",
      "|           transmission, for lorry           |    transmission, for lorry     |   RER    | lci-buses.xlsx |\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "Done!\n",
      "\n",
      "/////////////////////////// ELECTRICITY ////////////////////////////\n",
      "Update natural gas extraction datasets.\n",
      "Update efficiency of solar PV.\n",
      "Log of changes in photovoltaics efficiencies saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Create biomass markets.\n",
      "Empty old electricity datasets\n",
      "Create high voltage markets.\n",
      "Create medium voltage markets.\n",
      "Create low voltage markets.\n",
      "Log of deleted electricity markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Log of created electricity markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Done!\n",
      "Adjust efficiency of power plants...\n",
      "Log of changes in power plants efficiencies saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Rescale inventories and emissions for Gas CHP CCS\n",
      "Rescale inventories and emissions for Biomass ST\n",
      "Rescale inventories and emissions for Gas CHP\n",
      "Rescale inventories and emissions for Coal IGCC\n",
      "Rescale inventories and emissions for Coal IGCC CCS\n",
      "Rescale inventories and emissions for Oil ST\n",
      "Rescale inventories and emissions for Biomass IGCC CCS\n",
      "Rescale inventories and emissions for Coal CHP\n",
      "Rescale inventories and emissions for Gas CC CCS\n",
      "Rescale inventories and emissions for Nuclear\n",
      "Rescale inventories and emissions for Coal CHP CCS\n",
      "Rescale inventories and emissions for Oil CC\n",
      "Rescale inventories and emissions for Biomass CHP\n",
      "Rescale inventories and emissions for Biomass IGCC\n",
      "Rescale inventories and emissions for Oil CHP CCS\n",
      "Rescale inventories and emissions for Biomass CHP CCS\n",
      "Rescale inventories and emissions for Oil CHP\n",
      "Rescale inventories and emissions for Gas OC\n",
      "Rescale inventories and emissions for Oil CC CCS\n",
      "Rescale inventories and emissions for Gas CC\n",
      "Rescale inventories and emissions for Coal PC\n",
      "\n",
      "///////////////////////////// CEMENT //////////////////////////////\n",
      "\n",
      "Start integration of cement data...\n",
      "\n",
      "Log of deleted cement datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Log of created cement datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "\n",
      "Create new clinker production datasets and delete old datasets\n",
      "Adjusting emissions of hot pollutants for clinker production datasets...\n",
      "\n",
      "Create new clinker market datasets and delete old datasets\n",
      "Adjust clinker-to-cement ratio in \"unspecified cement\" datasets\n",
      "\n",
      "Create new cement market datasets\n",
      "\n",
      "Create new cement production datasets and adjust electricity consumption\n",
      "Done!\n",
      "\n",
      "////////////////////////////// STEEL //////////////////////////////\n",
      "Log of deleted steel datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Log of created steel datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Create steel markets for different regions\n",
      "Create new steel production datasets and empty old datasets\n",
      "Create pig iron production datasets\n",
      "Done!\n",
      "\n",
      "////////////////////////////// FUELS ///////////////////////////////\n",
      "Generate region-specific direct air capture processes.\n",
      "Generate region-specific hydrogen production pathways.\n",
      "Generate region-specific hydrogen supply chains.\n",
      "Generate region-specific biogas and syngas supply chains.\n",
      "Generate region-specific synthetic fuel supply chains.\n",
      "Generate region-specific biofuel supply chains.\n",
      "Generate new fuel markets.\n",
      "--> petrol, unleaded\n",
      "--> petrol, low-sulfur\n",
      "--> diesel, low-sulfur\n",
      "--> diesel\n",
      "Warning: ('nickel mine operation and benefication to nickel concentrate, 16% Ni', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sulfite pulp production, bleached', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('sulfite pulp production, bleached', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('ilmenite - magnetite mine operation', 'GLO') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('ilmenite - magnetite mine operation', 'GLO') has no fossil CO2 output flow.\n",
      "Warning: ('natural gas production', 'US') has no fossil CO2 output flow.\n",
      "Warning: ('natural gas production', 'US') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: ('Farming and supply of wheat straw', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('fuel supply for gasoline vehicles', 'CH') has no fossil CO2 output flow.\n",
      "Warning: ('lead acid battery, for lorry', 'RER') has no fossil CO2 output flow.\n",
      "Log of deleted fuel markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Log of created fuel markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Done!\n",
      "Write new database(s) to Brightway2.\n",
      "Prepare database 1.\n",
      "- check for duplicates...\n",
      "One or multiple duplicates detected. Removing them...\n",
      "- check for values format...\n",
      "- relinking exchanges...\n",
      "Done!\n",
      "41494 datasets\n",
      "1626226 exchanges\n",
      "0 unlinked exchanges\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 01/16/2023 17:32:25\n",
      "  Finished: 01/16/2023 17:34:41\n",
      "  Total time elapsed: 00:02:15\n",
      "  CPU %: 22.60\n",
      "  Memory %: 42.85\n",
      "Created database: image2025_SSP2-RCP19\n",
      "premise v.(1, 3, 0)\n",
      "+------------------------------------------------------------------+\n",
      "| Warning                                                          |\n",
      "+------------------------------------------------------------------+\n",
      "| Because some of the scenarios can yield LCI databases            |\n",
      "| containing net negative emission technologies (NET),             |\n",
      "| it is advised to account for biogenic CO2 flows when calculating |\n",
      "| Global Warming potential indicators.                             |\n",
      "| `premise_gwp` provides characterization factors for such flows.  |\n",
      "| It also provides factors for hydrogen emissions to air.          |\n",
      "|                                                                  |\n",
      "| Within your bw2 project:                                         |\n",
      "| from premise_gwp import add_premise_gwp                          |\n",
      "| add_premise_gwp()                                                |\n",
      "+------------------------------------------------------------------+\n",
      "+--------------------------------+----------------------------------+\n",
      "| Utils functions                | Description                      |\n",
      "+--------------------------------+----------------------------------+\n",
      "| clear_cache()                  | Clears the cache folder. Useful  |\n",
      "|                                | when updating `premise`or        |\n",
      "|                                | encountering issues with         |\n",
      "|                                | inventories.                     |\n",
      "+--------------------------------+----------------------------------+\n",
      "| get_regions_definition(model)  | Retrieves the list of countries  |\n",
      "|                                | for each region of the model.    |\n",
      "+--------------------------------+----------------------------------+\n",
      "| ndb.NewDatabase(...)           | Generates a summary of the most  |\n",
      "| ndb.generate_scenario_report() | important scenarios' variables.  |\n",
      "+--------------------------------+----------------------------------+\n",
      "Keep uncertainty data?\n",
      "NewDatabase(..., keep_uncertainty_data=True)\n",
      "\n",
      "Hide these messages?\n",
      "NewDatabase(..., quiet=True)\n",
      "\n",
      "//////////////////// EXTRACTING SOURCE DATABASE ////////////////////\n",
      "Done!\n",
      "\n",
      "////////////////// IMPORTING DEFAULT INVENTORIES ///////////////////\n",
      "Done!\n",
      "\n",
      "/////////////////////// EXTRACTING IAM DATA ////////////////////////\n",
      "Done!\n",
      "\n",
      "////////////////////////// TWO-WHEELERS ////////////////////////////\n",
      "Extracted 39 worksheets in 1.87 seconds\n",
      "Done!\n",
      "\n",
      "///////////////////////// PASSENGER CARS ///////////////////////////\n",
      "Extracted 1 worksheets in 9.72 seconds\n",
      "Done!\n",
      "\n",
      "////////////////// MEDIUM AND HEAVY DUTY TRUCKS ////////////////////\n",
      "Extracted 1 worksheets in 7.32 seconds\n",
      "Create fleet average vehicles...\n",
      "Done!\n",
      "\n",
      "////////////////////////////// BUSES ///////////////////////////////\n",
      "Extracted 1 worksheets in 1.48 seconds\n",
      "The following datasets to import already exist in the source database. They will not be imported\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "|                     Name                    |       Reference product        | Location |      File      |\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "|        assembly operation, for lorry        | assembly operation, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|               cabin, for lorry              |        cabin, for lorry        |   RER    | lci-buses.xlsx |\n",
      "|          exhaust system, for lorry          |   exhaust system, for lorry    |   RER    | lci-buses.xlsx |\n",
      "|     frame, blanks and saddle, for lorry     | frame, blanks and saddle, for  |   RER    | lci-buses.xlsx |\n",
      "|        fuel tank, for diesel vehicle        |           fuel tank            |   RER    | lci-buses.xlsx |\n",
      "|              gearbox, for lorry             |       gearbox, for lorry       |   RER    | lci-buses.xlsx |\n",
      "|    internal combustion engine, for lorry    | internal combustion engine, fo |   RER    | lci-buses.xlsx |\n",
      "|         lead acid battery, for lorry        |  lead acid battery, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|     other components, for electric lorry    | other components, for electric |   RER    | lci-buses.xlsx |\n",
      "| other components, for hybrid electric lorry | other components, for hybrid e |   RER    | lci-buses.xlsx |\n",
      "|         power electronics, for lorry        |  power electronics, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|             retarder, for lorry             |      retarder, for lorry       |   RER    | lci-buses.xlsx |\n",
      "|            suspension, for lorry            |     suspension, for lorry      |   RER    | lci-buses.xlsx |\n",
      "|         tires and wheels, for lorry         |  tires and wheels, for lorry   |   RER    | lci-buses.xlsx |\n",
      "|           transmission, for lorry           |    transmission, for lorry     |   RER    | lci-buses.xlsx |\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "Done!\n",
      "\n",
      "/////////////////////////// ELECTRICITY ////////////////////////////\n",
      "Update natural gas extraction datasets.\n",
      "Update efficiency of solar PV.\n",
      "Log of changes in photovoltaics efficiencies saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Create biomass markets.\n",
      "Empty old electricity datasets\n",
      "Create high voltage markets.\n",
      "Create medium voltage markets.\n",
      "Create low voltage markets.\n",
      "Log of deleted electricity markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Log of created electricity markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Done!\n",
      "Adjust efficiency of power plants...\n",
      "Log of changes in power plants efficiencies saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Rescale inventories and emissions for Gas CHP CCS\n",
      "Rescale inventories and emissions for Biomass ST\n",
      "Rescale inventories and emissions for Gas CHP\n",
      "Rescale inventories and emissions for Coal IGCC\n",
      "Rescale inventories and emissions for Coal IGCC CCS\n",
      "Rescale inventories and emissions for Oil ST\n",
      "Rescale inventories and emissions for Biomass IGCC CCS\n",
      "Rescale inventories and emissions for Coal CHP\n",
      "Rescale inventories and emissions for Gas CC CCS\n",
      "Rescale inventories and emissions for Nuclear\n",
      "Rescale inventories and emissions for Coal CHP CCS\n",
      "Rescale inventories and emissions for Oil CC\n",
      "Rescale inventories and emissions for Biomass CHP\n",
      "Rescale inventories and emissions for Biomass IGCC\n",
      "Rescale inventories and emissions for Oil CHP CCS\n",
      "Rescale inventories and emissions for Biomass CHP CCS\n",
      "Rescale inventories and emissions for Oil CHP\n",
      "Rescale inventories and emissions for Gas OC\n",
      "Rescale inventories and emissions for Oil CC CCS\n",
      "Rescale inventories and emissions for Gas CC\n",
      "Rescale inventories and emissions for Coal PC\n",
      "\n",
      "///////////////////////////// CEMENT //////////////////////////////\n",
      "\n",
      "Start integration of cement data...\n",
      "\n",
      "Log of deleted cement datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Log of created cement datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "\n",
      "Create new clinker production datasets and delete old datasets\n",
      "Adjusting emissions of hot pollutants for clinker production datasets...\n",
      "\n",
      "Create new clinker market datasets and delete old datasets\n",
      "Adjust clinker-to-cement ratio in \"unspecified cement\" datasets\n",
      "\n",
      "Create new cement market datasets\n",
      "\n",
      "Create new cement production datasets and adjust electricity consumption\n",
      "Done!\n",
      "\n",
      "////////////////////////////// STEEL //////////////////////////////\n",
      "Log of deleted steel datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Log of created steel datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Create steel markets for different regions\n",
      "Create new steel production datasets and empty old datasets\n",
      "Create pig iron production datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "////////////////////////////// FUELS ///////////////////////////////\n",
      "Generate region-specific direct air capture processes.\n",
      "Generate region-specific hydrogen production pathways.\n",
      "Generate region-specific hydrogen supply chains.\n",
      "Generate region-specific biogas and syngas supply chains.\n",
      "Generate region-specific synthetic fuel supply chains.\n",
      "Generate region-specific biofuel supply chains.\n",
      "Generate new fuel markets.\n",
      "--> petrol, unleaded\n",
      "--> petrol, low-sulfur\n",
      "--> diesel, low-sulfur\n",
      "--> diesel\n",
      "Warning: ('nickel mine operation and benefication to nickel concentrate, 16% Ni', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sulfite pulp production, bleached', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('sulfite pulp production, bleached', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('ilmenite - magnetite mine operation', 'GLO') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('ilmenite - magnetite mine operation', 'GLO') has no fossil CO2 output flow.\n",
      "Warning: ('natural gas production', 'US') has no fossil CO2 output flow.\n",
      "Warning: ('natural gas production', 'US') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('Farming and supply of wheat straw', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('fuel supply for gasoline vehicles', 'CH') has no fossil CO2 output flow.\n",
      "Warning: ('lead acid battery, for lorry', 'RER') has no fossil CO2 output flow.\n",
      "Log of deleted fuel markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Log of created fuel markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Done!\n",
      "Write new database(s) to Brightway2.\n",
      "Prepare database 1.\n",
      "- check for duplicates...\n",
      "One or multiple duplicates detected. Removing them...\n",
      "- check for values format...\n",
      "- relinking exchanges...\n",
      "Done!\n",
      "44032 datasets\n",
      "1837862 exchanges\n",
      "0 unlinked exchanges\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 01/16/2023 18:50:35\n",
      "  Finished: 01/16/2023 18:53:08\n",
      "  Total time elapsed: 00:02:32\n",
      "  CPU %: 22.60\n",
      "  Memory %: 48.36\n",
      "Created database: image2030_SSP2-RCP19\n",
      "premise v.(1, 3, 0)\n",
      "+------------------------------------------------------------------+\n",
      "| Warning                                                          |\n",
      "+------------------------------------------------------------------+\n",
      "| Because some of the scenarios can yield LCI databases            |\n",
      "| containing net negative emission technologies (NET),             |\n",
      "| it is advised to account for biogenic CO2 flows when calculating |\n",
      "| Global Warming potential indicators.                             |\n",
      "| `premise_gwp` provides characterization factors for such flows.  |\n",
      "| It also provides factors for hydrogen emissions to air.          |\n",
      "|                                                                  |\n",
      "| Within your bw2 project:                                         |\n",
      "| from premise_gwp import add_premise_gwp                          |\n",
      "| add_premise_gwp()                                                |\n",
      "+------------------------------------------------------------------+\n",
      "+--------------------------------+----------------------------------+\n",
      "| Utils functions                | Description                      |\n",
      "+--------------------------------+----------------------------------+\n",
      "| clear_cache()                  | Clears the cache folder. Useful  |\n",
      "|                                | when updating `premise`or        |\n",
      "|                                | encountering issues with         |\n",
      "|                                | inventories.                     |\n",
      "+--------------------------------+----------------------------------+\n",
      "| get_regions_definition(model)  | Retrieves the list of countries  |\n",
      "|                                | for each region of the model.    |\n",
      "+--------------------------------+----------------------------------+\n",
      "| ndb.NewDatabase(...)           | Generates a summary of the most  |\n",
      "| ndb.generate_scenario_report() | important scenarios' variables.  |\n",
      "+--------------------------------+----------------------------------+\n",
      "Keep uncertainty data?\n",
      "NewDatabase(..., keep_uncertainty_data=True)\n",
      "\n",
      "Hide these messages?\n",
      "NewDatabase(..., quiet=True)\n",
      "\n",
      "//////////////////// EXTRACTING SOURCE DATABASE ////////////////////\n",
      "Done!\n",
      "\n",
      "////////////////// IMPORTING DEFAULT INVENTORIES ///////////////////\n",
      "Done!\n",
      "\n",
      "/////////////////////// EXTRACTING IAM DATA ////////////////////////\n",
      "Done!\n",
      "\n",
      "////////////////////////// TWO-WHEELERS ////////////////////////////\n",
      "Extracted 39 worksheets in 1.52 seconds\n",
      "Done!\n",
      "\n",
      "///////////////////////// PASSENGER CARS ///////////////////////////\n",
      "Extracted 1 worksheets in 6.08 seconds\n",
      "Done!\n",
      "\n",
      "////////////////// MEDIUM AND HEAVY DUTY TRUCKS ////////////////////\n",
      "Extracted 1 worksheets in 10.01 seconds\n",
      "Create fleet average vehicles...\n",
      "Done!\n",
      "\n",
      "////////////////////////////// BUSES ///////////////////////////////\n",
      "Extracted 1 worksheets in 1.54 seconds\n",
      "The following datasets to import already exist in the source database. They will not be imported\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "|                     Name                    |       Reference product        | Location |      File      |\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "|        assembly operation, for lorry        | assembly operation, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|               cabin, for lorry              |        cabin, for lorry        |   RER    | lci-buses.xlsx |\n",
      "|          exhaust system, for lorry          |   exhaust system, for lorry    |   RER    | lci-buses.xlsx |\n",
      "|     frame, blanks and saddle, for lorry     | frame, blanks and saddle, for  |   RER    | lci-buses.xlsx |\n",
      "|        fuel tank, for diesel vehicle        |           fuel tank            |   RER    | lci-buses.xlsx |\n",
      "|              gearbox, for lorry             |       gearbox, for lorry       |   RER    | lci-buses.xlsx |\n",
      "|    internal combustion engine, for lorry    | internal combustion engine, fo |   RER    | lci-buses.xlsx |\n",
      "|         lead acid battery, for lorry        |  lead acid battery, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|     other components, for electric lorry    | other components, for electric |   RER    | lci-buses.xlsx |\n",
      "| other components, for hybrid electric lorry | other components, for hybrid e |   RER    | lci-buses.xlsx |\n",
      "|         power electronics, for lorry        |  power electronics, for lorry  |   RER    | lci-buses.xlsx |\n",
      "|             retarder, for lorry             |      retarder, for lorry       |   RER    | lci-buses.xlsx |\n",
      "|            suspension, for lorry            |     suspension, for lorry      |   RER    | lci-buses.xlsx |\n",
      "|         tires and wheels, for lorry         |  tires and wheels, for lorry   |   RER    | lci-buses.xlsx |\n",
      "|           transmission, for lorry           |    transmission, for lorry     |   RER    | lci-buses.xlsx |\n",
      "+---------------------------------------------+--------------------------------+----------+----------------+\n",
      "Done!\n",
      "\n",
      "/////////////////////////// ELECTRICITY ////////////////////////////\n",
      "Update natural gas extraction datasets.\n",
      "Update efficiency of solar PV.\n",
      "Log of changes in photovoltaics efficiencies saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Create biomass markets.\n",
      "Empty old electricity datasets\n",
      "Create high voltage markets.\n",
      "Create medium voltage markets.\n",
      "Create low voltage markets.\n",
      "Log of deleted electricity markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Log of created electricity markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Done!\n",
      "Adjust efficiency of power plants...\n",
      "Log of changes in power plants efficiencies saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Rescale inventories and emissions for Gas CHP CCS\n",
      "Rescale inventories and emissions for Biomass ST\n",
      "Rescale inventories and emissions for Gas CHP\n",
      "Rescale inventories and emissions for Coal IGCC\n",
      "Rescale inventories and emissions for Coal IGCC CCS\n",
      "Rescale inventories and emissions for Oil ST\n",
      "Rescale inventories and emissions for Biomass IGCC CCS\n",
      "Rescale inventories and emissions for Coal CHP\n",
      "Rescale inventories and emissions for Gas CC CCS\n",
      "Rescale inventories and emissions for Nuclear\n",
      "Rescale inventories and emissions for Coal CHP CCS\n",
      "Rescale inventories and emissions for Oil CC\n",
      "Rescale inventories and emissions for Biomass CHP\n",
      "Rescale inventories and emissions for Biomass IGCC\n",
      "Rescale inventories and emissions for Oil CHP CCS\n",
      "Rescale inventories and emissions for Biomass CHP CCS\n",
      "Rescale inventories and emissions for Oil CHP\n",
      "Rescale inventories and emissions for Gas OC\n",
      "Rescale inventories and emissions for Oil CC CCS\n",
      "Rescale inventories and emissions for Gas CC\n",
      "Rescale inventories and emissions for Coal PC\n",
      "\n",
      "///////////////////////////// CEMENT //////////////////////////////\n",
      "\n",
      "Start integration of cement data...\n",
      "\n",
      "Log of deleted cement datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "Log of created cement datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data/logs\n",
      "\n",
      "Create new clinker production datasets and delete old datasets\n",
      "Adjusting emissions of hot pollutants for clinker production datasets...\n",
      "\n",
      "Create new clinker market datasets and delete old datasets\n",
      "Adjust clinker-to-cement ratio in \"unspecified cement\" datasets\n",
      "\n",
      "Create new cement market datasets\n",
      "\n",
      "Create new cement production datasets and adjust electricity consumption\n",
      "Done!\n",
      "\n",
      "////////////////////////////// STEEL //////////////////////////////\n",
      "Log of deleted steel datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Log of created steel datasets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Create steel markets for different regions\n",
      "Create new steel production datasets and empty old datasets\n",
      "Create pig iron production datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "////////////////////////////// FUELS ///////////////////////////////\n",
      "Generate region-specific direct air capture processes.\n",
      "Generate region-specific hydrogen production pathways.\n",
      "Generate region-specific hydrogen supply chains.\n",
      "Generate region-specific biogas and syngas supply chains.\n",
      "Generate region-specific synthetic fuel supply chains.\n",
      "Generate region-specific biofuel supply chains.\n",
      "Generate new fuel markets.\n",
      "--> petrol, unleaded\n",
      "--> petrol, low-sulfur\n",
      "--> diesel, low-sulfur\n",
      "--> diesel\n",
      "Warning: ('nickel mine operation and benefication to nickel concentrate, 16% Ni', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sulfite pulp production, bleached', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('sulfite pulp production, bleached', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('ilmenite - magnetite mine operation', 'GLO') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RoW') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('ilmenite - magnetite mine operation', 'GLO') has no fossil CO2 output flow.\n",
      "Warning: ('natural gas production', 'US') has no fossil CO2 output flow.\n",
      "Warning: ('natural gas production', 'US') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('sawing and planing, azobe, air dried', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('gold-silver mine operation and beneficiation', 'CA-QC') has no fossil CO2 output flow.\n",
      "Warning: ('Farming and supply of wheat straw', 'RER') has no fossil CO2 output flow.\n",
      "Warning: ('fuel supply for gasoline vehicles', 'CH') has no fossil CO2 output flow.\n",
      "Warning: ('lead acid battery, for lorry', 'RER') has no fossil CO2 output flow.\n",
      "Log of deleted fuel markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Log of created fuel markets saved in C:\\Users\\SarahSchmidt\\anaconda3\\envs\\MoEWe2\\Lib\\site-packages\\premise\\data\\logs\n",
      "Done!\n",
      "Write new database(s) to Brightway2.\n",
      "Prepare database 1.\n",
      "- check for duplicates...\n",
      "One or multiple duplicates detected. Removing them...\n",
      "- check for values format...\n",
      "- relinking exchanges...\n",
      "Done!\n",
      "46233 datasets\n",
      "2030722 exchanges\n",
      "0 unlinked exchanges\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 01/16/2023 20:11:07\n",
      "  Finished: 01/16/2023 20:13:57\n",
      "  Total time elapsed: 00:02:49\n",
      "  CPU %: 23.40\n",
      "  Memory %: 51.63\n",
      "Created database: image2035_SSP2-RCP19\n"
     ]
    }
   ],
   "source": [
    "if general_info['Generate background system scenarios']=='yes':\n",
    "    if (general_info ['Type of background system scenarios']=='premise') or (general_info ['Type of background system scenarios']=='manual + premise'):\n",
    "        \n",
    "        premise_scenarios_dictlist=[]\n",
    "        premise_scenario_names_list=[]\n",
    "\n",
    "        for i in premise_scenarios.index:\n",
    "            for c in premise_scenarios.columns[3:]:\n",
    "                if premise_scenarios.loc[i,c]=='x':\n",
    "                    scenario_dict={\"model\":premise_scenarios.loc[i,'IAM'], \n",
    "                                   \"pathway\":premise_scenarios.loc[i,'SSP']+'-'+premise_scenarios.loc[i,'RCP'], \n",
    "                                   \"year\":c}\n",
    "                    scenario_name=premise_scenarios.loc[i,'IAM']+str(c)+'_'+premise_scenarios.loc[i,'SSP']+'-'+premise_scenarios.loc[i,'RCP']\n",
    "                    premise_scenarios_dictlist.append(scenario_dict)\n",
    "                    premise_scenario_names_list.append(scenario_name)\n",
    "       \n",
    "                    if scenario_name not in bw.databases:\n",
    "                        ndb = premise.NewDatabase(\n",
    "                            scenarios=[scenario_dict],\n",
    "                            source_db=eidb_default.name, # name of the database in the BW2 project. Must be a string.\n",
    "                            source_version=general_info['Database version'], # version of ecoinvent. Can be \"3.5\", \"3.6\", \"3.7\" or \"3.8\". Must be a string.\n",
    "                            key=encryption_key,# <-- decryption key\n",
    "                            quiet=True\n",
    "                            # to be requested from the library maintainers if you want ot use default scenarios included in `premise`\n",
    "                            )\n",
    "\n",
    "\n",
    "                        if len(premise_update)==8:\n",
    "                            ndb.update_all()\n",
    "                        else:\n",
    "                            if 'Electricity' in premise_update.index:\n",
    "                                ndb.update_electricity()\n",
    "                            if 'Cement' in premise_update.index:\n",
    "                                ndb.update_cement()\n",
    "                            if 'Steel' in premise_update.index:\n",
    "                                ndb.update_steel()\n",
    "                            if 'Fuels' in premise_update.index:\n",
    "                                ndb.update_fuels()\n",
    "                            if 'Cars' in premise_update.index:\n",
    "                                ndb.update_cars()\n",
    "                            if 'Trucks' in premise_update.index:\n",
    "                                ndb.update_trucks()\n",
    "                            if 'Two wheelers' in premise_update.index:\n",
    "                                ndb.update_two_wheelers()\n",
    "                            if 'Buses' in premise_update.index:\n",
    "                                ndb.update_buses()\n",
    "\n",
    "                        ndb.write_db_to_brightway(name=[scenario_name])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed2139",
   "metadata": {},
   "source": [
    "#### 1.3.5 Overview of databases to be included in the EWU-Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "439b3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs=[eidb]\n",
    "\n",
    "db_names_dict={}\n",
    "db_names_dict['default']=eidb.name\n",
    "n=1\n",
    "\n",
    "if general_info['Generate background system scenarios']=='yes':\n",
    "    if (general_info ['Type of background system scenarios']=='premise') or (general_info ['Type of background system scenarios']=='manual + premise'):\n",
    "        for scenario in premise_scenario_names_list:\n",
    "            dbs.append(bw.Database(scenario))\n",
    "            db='db'+str(n)\n",
    "            db_names_dict[db]=scenario\n",
    "            n=n+1\n",
    "\n",
    "db_names=[db for db in db_names_dict.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46dc0a",
   "metadata": {},
   "source": [
    "### 1.4 LCIA Methods, Normalization Factors & Weighting Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31fd91",
   "metadata": {},
   "source": [
    "**Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96b73ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCIAmethod_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='LCIA_Methods')\n",
    "LCIA_method_names=LCIAmethod_df['Acronym'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daaa1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCIA_methods=[]\n",
    "for i in LCIAmethod_df.index:\n",
    "    method=[m for m in bw.methods if m[0]==LCIAmethod_df.loc[i, 'Method_Part1'] and\n",
    "                                     m[1]==LCIAmethod_df.loc[i, 'Method_Part2'] and\n",
    "                                     m[2]==LCIAmethod_df.loc[i, 'Method_Part3']][0]\n",
    "    LCIA_methods.append(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f068473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCIAmethod_sheet_name='LCIA_Methods'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e6ef394",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCIAmethod_df=LCIAmethod_df.set_index('Acronym', drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff78b7b",
   "metadata": {},
   "source": [
    "**Normalization Factors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d32a2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs=LCIAmethod_df['Normalization Factor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2c770",
   "metadata": {},
   "source": [
    "**Weighting Factors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51085b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighting_sheet_name='Weighting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df273665",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighting=pd.read_excel(\"ExcelTool_GeneratorInput_Template.xlsx\", sheet_name=\"Weighting\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e20ba7",
   "metadata": {},
   "source": [
    "## 2. Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39294164",
   "metadata": {},
   "source": [
    "### 2.1 Life Cycle Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655c331",
   "metadata": {},
   "source": [
    "#### 2.1.1 Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e375539",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17f57985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoinvent 3.7.1_cutoff_ecoSpold02\n",
      "image2025_SSP2-RCP19\n",
      "image2030_SSP2-RCP19\n",
      "image2035_SSP2-RCP19\n"
     ]
    }
   ],
   "source": [
    "for db in dbs:\n",
    "    print(db.name)\n",
    "    for i in activity_df.index:\n",
    "        if len([act for act in db if act['code']==activity_df.loc[i,'Activity code']])==0:\n",
    "            activity = db.new_activity(code = activity_df.loc[i,'Activity code'], name = activity_df.loc[i,'Activity name'], unit = activity_df.loc[i,'Unit'], location = activity_df.loc[i,'Location'])\n",
    "            activity.save()\n",
    "        else:\n",
    "            activity=[act for act in db if act['code']==activity_df.loc[i,'Activity code']][0]\n",
    "            if activity['name']!=activity_df.loc[i,'Activity name']:\n",
    "                print(\"Error: Activity name\", activity['name'], activity_df.loc[i,'Activity name'])\n",
    "            if activity['location']!=activity_df.loc[i,'Location']:\n",
    "                print(\"Error: Activity location\", activity['location'], activity_df.loc[i,'Location'])\n",
    "            if activity['unit']!=activity_df.loc[i,'Unit']:\n",
    "                print(\"Error: Activity unit\", activity['unit'], activity_df.loc[i,'Unit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ef177",
   "metadata": {},
   "source": [
    "#### 2.2.2 Exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2909979",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Exchanges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4219705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoinvent 3.7.1_cutoff_ecoSpold02\n",
      "image2025_SSP2-RCP19\n",
      "image2030_SSP2-RCP19\n",
      "image2035_SSP2-RCP19\n"
     ]
    }
   ],
   "source": [
    "for db in dbs:\n",
    "    print(db.name)\n",
    "    for actcode in exchanges_df['activity code'].unique():\n",
    "        act_exchanges_df=exchanges_df[exchanges_df['activity code']==actcode]\n",
    "        act=[act for act in db if act['code']==actcode][0]\n",
    "        act.exchanges().delete()\n",
    "        for i in act_exchanges_df.index:\n",
    "            if (act_exchanges_df.loc[i,'type']=='technosphere') or (act_exchanges_df.loc[i,'type']=='production'):\n",
    "                exc_input=[act for act in db if act['code']==act_exchanges_df.loc[i,'input code']][0]\n",
    "            if act_exchanges_df.loc[i,'type']=='biosphere':\n",
    "                exc_input=[act for act in biosphere if act['code']==act_exchanges_df.loc[i,'input code']][0]\n",
    "            act.new_exchange(input = exc_input.key, amount = act_exchanges_df.loc[i,'amount'], \n",
    "                                 unit = act_exchanges_df.loc[i,'input unit'], type = act_exchanges_df.loc[i,'type']).save() \n",
    "            act.save()             \n",
    "\n",
    "            exc=[exc for exc in act.exchanges() if exc['input']==exc_input.key][0]\n",
    "\n",
    "            #import material flow tag\n",
    "            if (exc_input['code'] in activity_df['Activity code']) & (exc_input['unit'] == 'kilogram'):\n",
    "                exc['tag']='material flow'\n",
    "                exc.save()\n",
    "                act.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2f42a",
   "metadata": {},
   "source": [
    "#### 1.3.4 Manual Background Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "031a4fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>background scenario</th>\n",
       "      <th>database</th>\n",
       "      <th>input</th>\n",
       "      <th>input code</th>\n",
       "      <th>input unit</th>\n",
       "      <th>input location / biosphere category</th>\n",
       "      <th>activity</th>\n",
       "      <th>activity code</th>\n",
       "      <th>activity location</th>\n",
       "      <th>amount</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2025_SSP2-RCP19</td>\n",
       "      <td>avoided emissions, CO2</td>\n",
       "      <td>avoidedCO2</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.123707</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2025_SSP2-RCP19</td>\n",
       "      <td>Carbon dioxide, fossil</td>\n",
       "      <td>aa7cac3a-3625-41d4-bc54-33e2cf11ec46</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>('air', 'non-urban air or from high stacks')</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.122120</td>\n",
       "      <td>biosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2025_SSP2-RCP19</td>\n",
       "      <td>market for wood pellet</td>\n",
       "      <td>9c663a9f4aa6d200ced09fd7a3ed7f98</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>RER</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>-1.998235</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2025_SSP2-RCP19</td>\n",
       "      <td>market for hard coal</td>\n",
       "      <td>a72db9f7595317eda5100fff717c584d</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>RoW</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2025_SSP2-RCP19</td>\n",
       "      <td>avoided emissions, CO2</td>\n",
       "      <td>avoidedCO2</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>substitution of fuels in cement kilns, polyeth...</td>\n",
       "      <td>CemKiln-FuelSubst-PE</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.162417</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2035_SSP2-RCP19</td>\n",
       "      <td>heat and power co-generation, natural gas, com...</td>\n",
       "      <td>ba05d6265dc78e070c8ce7ae01828dfe</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>RoW</td>\n",
       "      <td>market for heat, mix, export countries</td>\n",
       "      <td>heat_mix_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2035_SSP2-RCP19</td>\n",
       "      <td>natural gas, burned in gas motor, for storage</td>\n",
       "      <td>5782508bdc29a389625856679cb35c82</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>RoW</td>\n",
       "      <td>market for heat, mix, export countries</td>\n",
       "      <td>heat_mix_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2035_SSP2-RCP19</td>\n",
       "      <td>heat production, at hot water tank, solar+elec...</td>\n",
       "      <td>374031b1fbc7d00b316f69b007133d59</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>CH</td>\n",
       "      <td>market for heat, mix, export countries</td>\n",
       "      <td>heat_mix_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2035_SSP2-RCP19</td>\n",
       "      <td>heat production, air-water heat pump 10kW</td>\n",
       "      <td>85577cff356913040aa8e0cb9dd39bd8</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>RoW</td>\n",
       "      <td>market for heat, mix, export countries</td>\n",
       "      <td>heat_mix_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>heat+cement</td>\n",
       "      <td>image2035_SSP2-RCP19</td>\n",
       "      <td>heat and power co-generation, natural gas, con...</td>\n",
       "      <td>6c4c252f3b909266678612c535185a48</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>RoW</td>\n",
       "      <td>market for heat, mix, export countries</td>\n",
       "      <td>heat_mix_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>technosphere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   background scenario              database  \\\n",
       "0          heat+cement  image2025_SSP2-RCP19   \n",
       "1          heat+cement  image2025_SSP2-RCP19   \n",
       "2          heat+cement  image2025_SSP2-RCP19   \n",
       "3          heat+cement  image2025_SSP2-RCP19   \n",
       "4          heat+cement  image2025_SSP2-RCP19   \n",
       "..                 ...                   ...   \n",
       "91         heat+cement  image2035_SSP2-RCP19   \n",
       "92         heat+cement  image2035_SSP2-RCP19   \n",
       "93         heat+cement  image2035_SSP2-RCP19   \n",
       "94         heat+cement  image2035_SSP2-RCP19   \n",
       "95         heat+cement  image2035_SSP2-RCP19   \n",
       "\n",
       "                                                input  \\\n",
       "0                              avoided emissions, CO2   \n",
       "1                              Carbon dioxide, fossil   \n",
       "2                              market for wood pellet   \n",
       "3                                market for hard coal   \n",
       "4                              avoided emissions, CO2   \n",
       "..                                                ...   \n",
       "91  heat and power co-generation, natural gas, com...   \n",
       "92      natural gas, burned in gas motor, for storage   \n",
       "93  heat production, at hot water tank, solar+elec...   \n",
       "94          heat production, air-water heat pump 10kW   \n",
       "95  heat and power co-generation, natural gas, con...   \n",
       "\n",
       "                              input code input unit  \\\n",
       "0                             avoidedCO2   kilogram   \n",
       "1   aa7cac3a-3625-41d4-bc54-33e2cf11ec46   kilogram   \n",
       "2       9c663a9f4aa6d200ced09fd7a3ed7f98   kilogram   \n",
       "3       a72db9f7595317eda5100fff717c584d   kilogram   \n",
       "4                             avoidedCO2   kilogram   \n",
       "..                                   ...        ...   \n",
       "91      ba05d6265dc78e070c8ce7ae01828dfe  megajoule   \n",
       "92      5782508bdc29a389625856679cb35c82  megajoule   \n",
       "93      374031b1fbc7d00b316f69b007133d59  megajoule   \n",
       "94      85577cff356913040aa8e0cb9dd39bd8  megajoule   \n",
       "95      6c4c252f3b909266678612c535185a48  megajoule   \n",
       "\n",
       "             input location / biosphere category  \\\n",
       "0                                            GLO   \n",
       "1   ('air', 'non-urban air or from high stacks')   \n",
       "2                                            RER   \n",
       "3                                            RoW   \n",
       "4                                            GLO   \n",
       "..                                           ...   \n",
       "91                                           RoW   \n",
       "92                                           RoW   \n",
       "93                                            CH   \n",
       "94                                           RoW   \n",
       "95                                           RoW   \n",
       "\n",
       "                                             activity         activity code  \\\n",
       "0   substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "1   substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "2   substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "3   substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "4   substitution of fuels in cement kilns, polyeth...  CemKiln-FuelSubst-PE   \n",
       "..                                                ...                   ...   \n",
       "91             market for heat, mix, export countries       heat_mix_export   \n",
       "92             market for heat, mix, export countries       heat_mix_export   \n",
       "93             market for heat, mix, export countries       heat_mix_export   \n",
       "94             market for heat, mix, export countries       heat_mix_export   \n",
       "95             market for heat, mix, export countries       heat_mix_export   \n",
       "\n",
       "   activity location    amount          type  \n",
       "0                 DE -0.123707  technosphere  \n",
       "1                 DE  2.122120     biosphere  \n",
       "2                 DE -1.998235  technosphere  \n",
       "3                 DE  0.000000  technosphere  \n",
       "4                 DE -0.162417  technosphere  \n",
       "..               ...       ...           ...  \n",
       "91               GLO  0.000000  technosphere  \n",
       "92               GLO  0.000000  technosphere  \n",
       "93               GLO  0.027778  technosphere  \n",
       "94               GLO  0.777778  technosphere  \n",
       "95               GLO  0.055556  technosphere  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_scenarios=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', \n",
    "                                   sheet_name='BackgroundScenarios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ec9dfe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database has already been imported.\n",
      "Database has already been imported.\n",
      "Database has already been imported.\n"
     ]
    }
   ],
   "source": [
    "if general_info['Generate background system scenarios']=='yes':\n",
    "    if (general_info ['Type of background system scenarios']=='manual') or (general_info ['Type of background system scenarios']=='manual + premise'):\n",
    "        \n",
    "        background_scenario_names_list=[]\n",
    "        \n",
    "        for bs in background_scenarios['background scenario'].unique():\n",
    "            sub_df=background_scenarios[background_scenarios['background scenario']==bs]          \n",
    "            for database in sub_df['database'].unique():\n",
    "                db_name=database+'_'+bs\n",
    "                if db_name not in bw.databases:\n",
    "                    db=bw.Database(database)\n",
    "                    db.copy(db_name)\n",
    "                else:\n",
    "                    print(\"Database has already been imported.\")\n",
    "                \n",
    "                if db_name not in background_scenario_names_list:\n",
    "                    background_scenario_names_list.append(db_name)\n",
    "            \n",
    "            \n",
    "        if general_info['Handling of manual background system scenarios']=='adapt exchange amounts':\n",
    "            for i in background_scenarios.index:\n",
    "                db_name=background_scenarios.loc[i,'database']+'_'+background_scenarios.loc[i,'background scenario']\n",
    "                bsdb=bw.Database(db_name)\n",
    "                act=bsdb.get(background_scenarios.loc[i,'activity code'])\n",
    "                exc=[exc for exc in act.exchanges() if exc.input.as_dict()['code']==background_scenarios.loc[i,'input code']][0]\n",
    "\n",
    "                exc['amount']=background_scenarios.loc[i,'amount']\n",
    "                exc.save()\n",
    "                    \n",
    "        if general_info['Handling of manual background system scenarios']=='new exchanges':\n",
    "            for bs in background_scenarios['background scenario'].unique():\n",
    "                sub_df=background_scenarios[background_scenarios['background scenario']==bs]\n",
    "                for database in sub_df['database'].unique():\n",
    "                    sub_sub_df=sub_df[sub_df['database']==database]\n",
    "                    for actcode in sub_sub_df['activity code'].unique():\n",
    "                        sub_sub_sub_df=sub_sub_df[sub_sub_df['activity code']==actcode]\n",
    "                        db_name=database+'_'+bs\n",
    "                        bsdb=bw.Database(db_name)\n",
    "                        act=bsdb.get(actcode)\n",
    "                        act.technosphere().delete()\n",
    "                        act.biosphere().delete()\n",
    "                        for i in sub_sub_sub_df.index:\n",
    "                            if sub_sub_sub_df.loc[i,'type']=='technosphere':\n",
    "                                input_act=bsdb.get(sub_sub_sub_df.loc[i,'input code'])\n",
    "                            else:\n",
    "                                input_act=biosphere.get(sub_sub_sub_df.loc[i,'input code'])\n",
    "                            act.new_exchange(input=input_act.key,\n",
    "                                            unit=input_act['unit'],\n",
    "                                            amount=sub_sub_sub_df.loc[i,'amount'],\n",
    "                                            type=sub_sub_sub_df.loc[i,'type']).save()\n",
    "                            act.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd52f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if general_info['Generate background system scenarios']=='yes':\n",
    "    if (general_info ['Type of background system scenarios']=='manual') or (general_info['Type of background system scenarios']=='manual + premise'):\n",
    "        for scenario in background_scenario_names_list:\n",
    "            dbs.append(bw.Database(scenario))\n",
    "            db='db'+str(n)\n",
    "            db_names_dict[db]=scenario\n",
    "            n=n+1\n",
    "            \n",
    "db_names=[db for db in db_names_dict.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c780b95",
   "metadata": {},
   "source": [
    "### 2.2 Modular Life Cycle Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c2eca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80533ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_system=[]\n",
    "for actcode in foreground_system_codes:\n",
    "    foreground_system.append(eidb.get(actcode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a78cb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_system_groups={}\n",
    "for ac,actcode in enumerate(foreground_system_codes):\n",
    "    foreground_system_groups[actcode]=ac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9fe85",
   "metadata": {},
   "source": [
    "#### 2.2.1 LCI to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9888da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>input code</th>\n",
       "      <th>input unit</th>\n",
       "      <th>input location</th>\n",
       "      <th>activity</th>\n",
       "      <th>activity code</th>\n",
       "      <th>activity location</th>\n",
       "      <th>amount</th>\n",
       "      <th>type</th>\n",
       "      <th>material flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>production</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>substitution of coal</td>\n",
       "      <td>coal-Substitution</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.085495</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>substitution of lignite</td>\n",
       "      <td>lignite-Substitution</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.743553</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>substitution of petcoke</td>\n",
       "      <td>petcoke-Substitution</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.023270</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>substitution of heavy fuel oil</td>\n",
       "      <td>heavyfueloil-Substitution</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>GLO</td>\n",
       "      <td>substitution of fuels in cement kilns, mixed p...</td>\n",
       "      <td>CemKiln-FuelSubst-MP</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>treatment of municipal solid waste, incineration</td>\n",
       "      <td>73c9bb8a89bfa6026bce836e3efddb74</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>RoW</td>\n",
       "      <td>thermochemical recycling, MP</td>\n",
       "      <td>ChemRecMP_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>substitution of heat</td>\n",
       "      <td>heat-Substitution_export</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>GLO</td>\n",
       "      <td>thermochemical recycling, MP</td>\n",
       "      <td>ChemRecMP_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>-0.471600</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>transport, freight, lorry &gt;32 metric ton, EURO5</td>\n",
       "      <td>lorry_32</td>\n",
       "      <td>ton kilometer</td>\n",
       "      <td>RER</td>\n",
       "      <td>thermochemical recycling, MP</td>\n",
       "      <td>ChemRecMP_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>Water</td>\n",
       "      <td>09872080-d143-4fb1-a3a5-647b077107ff</td>\n",
       "      <td>cubic meter</td>\n",
       "      <td>('air', 'non-urban air or from high stacks')</td>\n",
       "      <td>thermochemical recycling, MP</td>\n",
       "      <td>ChemRecMP_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>biosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>Carbon dioxide, fossil</td>\n",
       "      <td>aa7cac3a-3625-41d4-bc54-33e2cf11ec46</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>('air', 'non-urban air or from high stacks')</td>\n",
       "      <td>thermochemical recycling, MP</td>\n",
       "      <td>ChemRecMP_export</td>\n",
       "      <td>GLO</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>biosphere</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3944 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     substitution of fuels in cement kilns, mixed p...   \n",
       "1                                  substitution of coal   \n",
       "2                               substitution of lignite   \n",
       "3                               substitution of petcoke   \n",
       "4                        substitution of heavy fuel oil   \n",
       "...                                                 ...   \n",
       "3939   treatment of municipal solid waste, incineration   \n",
       "3940                               substitution of heat   \n",
       "3941    transport, freight, lorry >32 metric ton, EURO5   \n",
       "3942                                              Water   \n",
       "3943                             Carbon dioxide, fossil   \n",
       "\n",
       "                                input code     input unit  \\\n",
       "0                     CemKiln-FuelSubst-MP       kilogram   \n",
       "1                        coal-Substitution       kilogram   \n",
       "2                     lignite-Substitution       kilogram   \n",
       "3                     petcoke-Substitution       kilogram   \n",
       "4                heavyfueloil-Substitution       kilogram   \n",
       "...                                    ...            ...   \n",
       "3939      73c9bb8a89bfa6026bce836e3efddb74       kilogram   \n",
       "3940              heat-Substitution_export      megajoule   \n",
       "3941                              lorry_32  ton kilometer   \n",
       "3942  09872080-d143-4fb1-a3a5-647b077107ff    cubic meter   \n",
       "3943  aa7cac3a-3625-41d4-bc54-33e2cf11ec46       kilogram   \n",
       "\n",
       "                                    input location  \\\n",
       "0                                               DE   \n",
       "1                                              GLO   \n",
       "2                                              GLO   \n",
       "3                                              GLO   \n",
       "4                                              GLO   \n",
       "...                                            ...   \n",
       "3939                                           RoW   \n",
       "3940                                           GLO   \n",
       "3941                                           RER   \n",
       "3942  ('air', 'non-urban air or from high stacks')   \n",
       "3943  ('air', 'non-urban air or from high stacks')   \n",
       "\n",
       "                                               activity         activity code  \\\n",
       "0     substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "1     substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "2     substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "3     substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "4     substitution of fuels in cement kilns, mixed p...  CemKiln-FuelSubst-MP   \n",
       "...                                                 ...                   ...   \n",
       "3939                       thermochemical recycling, MP      ChemRecMP_export   \n",
       "3940                       thermochemical recycling, MP      ChemRecMP_export   \n",
       "3941                       thermochemical recycling, MP      ChemRecMP_export   \n",
       "3942                       thermochemical recycling, MP      ChemRecMP_export   \n",
       "3943                       thermochemical recycling, MP      ChemRecMP_export   \n",
       "\n",
       "     activity location    amount          type material flow  \n",
       "0                   DE -1.000000    production         False  \n",
       "1                   DE -0.085495  technosphere         False  \n",
       "2                   DE -0.743553  technosphere         False  \n",
       "3                   DE -0.023270  technosphere         False  \n",
       "4                   DE -0.001758  technosphere         False  \n",
       "...                ...       ...           ...           ...  \n",
       "3939               GLO -0.050000  technosphere         False  \n",
       "3940               GLO -0.471600  technosphere         False  \n",
       "3941               GLO  0.012000  technosphere         False  \n",
       "3942               GLO  0.019900     biosphere         False  \n",
       "3943               GLO  0.198000     biosphere         False  \n",
       "\n",
       "[3944 rows x 10 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCI_df=pd.DataFrame()\n",
    "i=0\n",
    "\n",
    "for act in foreground_system:   \n",
    "    act_name=act.as_dict()['name']\n",
    "    act_code=act.as_dict()['code']\n",
    "    act_unit=act.as_dict()['unit']\n",
    "    act_location=act.as_dict()['location']\n",
    "    #production exchange\n",
    "    LCI_df.loc[i,'input']=act_name\n",
    "    LCI_df.loc[i,'input code']=act_code\n",
    "    LCI_df.loc[i,'input unit']=act_unit\n",
    "    LCI_df.loc[i,'input location']=act_location\n",
    "    LCI_df.loc[i,'activity']=act_name\n",
    "    LCI_df.loc[i,'activity code']=act_code\n",
    "    LCI_df.loc[i,'activity location']=act_location\n",
    "    if len([exc for exc in eidb.get(act_code).production()]) >0:\n",
    "        LCI_df.loc[i,'amount']=[exc.amount for exc in eidb.get(act_code).production()][0]\n",
    "    else:\n",
    "        LCI_df.loc[i,'amount']=1\n",
    "    LCI_df.loc[i,'type']='production'\n",
    "    LCI_df.loc[i,'material flow']=False\n",
    "    i=i+1\n",
    "\n",
    "    #technosphere exchanges\n",
    "    for exc in act.technosphere():\n",
    "        LCI_df.loc[i,'input']=exc.input.as_dict()['name']\n",
    "        LCI_df.loc[i,'input code']=exc.input.as_dict()['code']\n",
    "        LCI_df.loc[i,'input unit']=exc.input.as_dict()['unit']\n",
    "        LCI_df.loc[i,'input location']=exc.input.as_dict()['location']\n",
    "        LCI_df.loc[i,'activity']=act_name\n",
    "        LCI_df.loc[i,'activity code']=act_code\n",
    "        LCI_df.loc[i,'activity location']=act_location\n",
    "        LCI_df.loc[i,'amount']=exc.amount\n",
    "        LCI_df.loc[i,'type']='technosphere'\n",
    "        if exc.input.as_dict()['code'] in foreground_system_codes:\n",
    "            LCI_df.loc[i,'material flow']=True\n",
    "        else:\n",
    "            LCI_df.loc[i,'material flow']=False\n",
    "        i=i+1\n",
    "        \n",
    "    #biosphere exchanges\n",
    "    for exc in act.biosphere():\n",
    "        LCI_df.loc[i,'input']=exc.input.as_dict()['name']\n",
    "        LCI_df.loc[i,'input code']=exc.input.as_dict()['code']\n",
    "        LCI_df.loc[i,'input unit']=exc.input.as_dict()['unit']\n",
    "        LCI_df.loc[i,'input location']=str(exc.input.as_dict()['categories'])\n",
    "        LCI_df.loc[i,'activity']=act_name\n",
    "        LCI_df.loc[i,'activity code']=act_code\n",
    "        LCI_df.loc[i,'activity location']=act_location\n",
    "        LCI_df.loc[i,'amount']=exc.amount\n",
    "        LCI_df.loc[i,'type']='biosphere'\n",
    "        LCI_df.loc[i,'material flow']=False\n",
    "        i=i+1\n",
    "\n",
    "LCI_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae2f67",
   "metadata": {},
   "source": [
    "#### 2.2.2 Add parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa411afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel sheet name (EWU-Dashboard)\n",
    "params_sheet_name='Parameter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3bd5ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios=['default']\n",
    "\n",
    "for s in range(n_scenarios):\n",
    "    scenarios.append('S'+str(s+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b1bfe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter-ID</th>\n",
       "      <th>Parameter Description</th>\n",
       "      <th>Default Amount</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Transport of LWP Waste to Sorting</td>\n",
       "      <td>9.500000e-03</td>\n",
       "      <td>ton kilometer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Collection of LWP Waste</td>\n",
       "      <td>1.200000e-01</td>\n",
       "      <td>ton kilometer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>MBT, electricity consumption</td>\n",
       "      <td>6.186000e-02</td>\n",
       "      <td>kilowatt hour</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>MBT, diesel consumption</td>\n",
       "      <td>8.048250e-02</td>\n",
       "      <td>megajoule</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>MBT, facility construction</td>\n",
       "      <td>2.500000e-10</td>\n",
       "      <td>unit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>P347</td>\n",
       "      <td>waste collection - TP2 (TP_DRS_SingleUse)</td>\n",
       "      <td>1.705263e-01</td>\n",
       "      <td>-</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>P348</td>\n",
       "      <td>waste collection - TP3 (TP_LWP)</td>\n",
       "      <td>3.692416e-01</td>\n",
       "      <td>-</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>P349</td>\n",
       "      <td>waste collection - TP4 (TP_RW_Inc)</td>\n",
       "      <td>1.913953e-01</td>\n",
       "      <td>-</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>P350</td>\n",
       "      <td>waste collection - TP5 (TP_RW_MBT)</td>\n",
       "      <td>3.837097e-02</td>\n",
       "      <td>-</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>P351</td>\n",
       "      <td>waste collection - TP6 (TP_Littering)</td>\n",
       "      <td>5.000000e-03</td>\n",
       "      <td>-</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Parameter-ID                      Parameter Description  Default Amount  \\\n",
       "0             P1          Transport of LWP Waste to Sorting    9.500000e-03   \n",
       "1             P2                    Collection of LWP Waste    1.200000e-01   \n",
       "2             P3               MBT, electricity consumption    6.186000e-02   \n",
       "3             P4                    MBT, diesel consumption    8.048250e-02   \n",
       "4             P5                 MBT, facility construction    2.500000e-10   \n",
       "..           ...                                        ...             ...   \n",
       "346         P347  waste collection - TP2 (TP_DRS_SingleUse)    1.705263e-01   \n",
       "347         P348            waste collection - TP3 (TP_LWP)    3.692416e-01   \n",
       "348         P349         waste collection - TP4 (TP_RW_Inc)    1.913953e-01   \n",
       "349         P350         waste collection - TP5 (TP_RW_MBT)    3.837097e-02   \n",
       "350         P351      waste collection - TP6 (TP_Littering)    5.000000e-03   \n",
       "\n",
       "              Unit  Group  \n",
       "0    ton kilometer    NaN  \n",
       "1    ton kilometer    NaN  \n",
       "2    kilowatt hour    NaN  \n",
       "3        megajoule    NaN  \n",
       "4             unit    NaN  \n",
       "..             ...    ...  \n",
       "346              -    4.0  \n",
       "347              -    4.0  \n",
       "348              -    4.0  \n",
       "349              -    4.0  \n",
       "350              -    4.0  \n",
       "\n",
       "[351 rows x 5 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Parameters')\n",
    "param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dcba3a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameter_df=pd.DataFrame()\n",
    "p=1\n",
    "\n",
    "parameter_df.loc[0,'Parameter-ID']='P0'\n",
    "parameter_df.loc[0,'Parameter']='Waste Quantity'\n",
    "for s in range(n_scenarios):\n",
    "    parameter_df.loc[0,'Parameter Value - S'+str(s+1)]=WQ_kg\n",
    "parameter_df.loc[0,'Parameter Value - default']=WQ_kg\n",
    "parameter_df.loc[0,'Unit']='kilogram'\n",
    "\n",
    "if general_info['Type of parameterization']=='predefined parameters':\n",
    "    param_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Parameters')\n",
    "    for i in param_df.index:\n",
    "        parameter_df.loc[i+1,'Parameter-ID']=param_df.loc[i,'Parameter-ID']\n",
    "        parameter_df.loc[i+1,'Parameter']=param_df.loc[i,'Parameter Description']\n",
    "        parameter_df.loc[i+1,'Unit']=param_df.loc[i,'Unit']  \n",
    "        parameter_df.loc[i+1,'Group']=param_df.loc[i,'Group']  \n",
    "        for s in range(n_scenarios):\n",
    "            parameter_df.loc[i+1,'Parameter Value - S'+str(s+1)]=param_df.loc[i,'Default Amount']  \n",
    "        parameter_df.loc[i+1,'Parameter Value - default']=param_df.loc[i,'Default Amount']\n",
    "        \n",
    "    param_exchanges_df=exchanges_df[pd.isnull(exchanges_df['Formula'])==False]\n",
    "    for param_ind in param_exchanges_df.index:\n",
    "        exc_ind=LCI_df[(LCI_df['input code']==param_exchanges_df.loc[param_ind, 'input code'])&\n",
    "                       (LCI_df['activity code']==param_exchanges_df.loc[param_ind, 'activity code'])].index[0]\n",
    "        LCI_df.loc[exc_ind, 'formula']=param_exchanges_df.loc[param_ind, 'Formula']\n",
    "    \n",
    "\n",
    "if general_info['Type of parameterization']=='automatically generated parameters':\n",
    "    if general_info['Parameterize exchanges']=='technosphere':\n",
    "        for i in LCI_df.index:\n",
    "            if LCI_df.loc[i,'type']=='technosphere':\n",
    "                param='P'+str(p+1)\n",
    "                LCI_df.loc[i,'formula']=param\n",
    "                parameter_df.loc[p,'Parameter-ID']=param\n",
    "                parameter_df.loc[p,'Parameter']='FROM: '+LCI_df.loc[i,'input']+' ('+LCI_df.loc[i,'input location']+', '+LCI_df.loc[i,'input unit']+'), TO: '+LCI_df.loc[i,'activity']+'('+LCI_df.loc[i,'activity location']+')'\n",
    "                parameter_df.loc[p,'Unit']=LCI_df.loc[i,'input unit']       \n",
    "                for s in range(n_scenarios):\n",
    "                    parameter_df.loc[p,'Parameter Value - S'+str(s+1)]=LCI_df.loc[i,'amount']\n",
    "                parameter_df.loc[p,'Parameter Value - default']=LCI_df.loc[i,'amount']\n",
    "                if LCI_df.loc[i,'material flow'] == True:\n",
    "                    parameter_df.loc[p, 'Group']=foreground_system_groups[LCI_df.loc[i,'activity code']]\n",
    "                p=p+1\n",
    "                \n",
    "    if general_info['Parameterize exchanges']=='biosphere':\n",
    "        for i in LCI_df.index:\n",
    "            if LCI_df.loc[i,'type']=='biosphere':\n",
    "                param='P'+str(p+1)\n",
    "                LCI_df.loc[i,'formula']=param\n",
    "                parameter_df.loc[p,'Parameter-ID']=param\n",
    "                parameter_df.loc[p,'Parameter']='FROM: '+LCI_df.loc[i,'input']+' ('+LCI_df.loc[i,'input location']+', '+LCI_df.loc[i,'input unit']+'), TO: '+LCI_df.loc[i,'activity']+'('+LCI_df.loc[i,'activity location']+')'\n",
    "                parameter_df.loc[p,'Unit']=LCI_df.loc[i,'input unit']       \n",
    "                for s in range(n_scenarios):\n",
    "                    parameter_df.loc[p,'Parameter Value - S'+str(s+1)]=LCI_df.loc[i,'amount']\n",
    "                parameter_df.loc[p,'Parameter Value - default']=LCI_df.loc[i,'amount']\n",
    "                if LCI_df.loc[i,'material flow'] == True:\n",
    "                    parameter_df.loc[p, 'Group']=foreground_system_groups[LCI_df.loc[i,'activity code']]\n",
    "                p=p+1\n",
    "                \n",
    "    if general_info['Parameterize exchanges']=='technosphere & biosphere':\n",
    "        for i in LCI_df.index:\n",
    "            if LCI_df.loc[i,'type']!='production':\n",
    "                param='P'+str(p+1)\n",
    "                LCI_df.loc[i,'formula']=param\n",
    "                parameter_df.loc[p,'Parameter-ID']=param\n",
    "                parameter_df.loc[p,'Parameter']='FROM: '+LCI_df.loc[i,'input']+' ('+LCI_df.loc[i,'input location']+', '+LCI_df.loc[i,'input unit']+'), TO: '+LCI_df.loc[i,'activity']+'('+LCI_df.loc[i,'activity location']+')'\n",
    "                parameter_df.loc[p,'Unit']=LCI_df.loc[i,'input unit']       \n",
    "                for s in range(n_scenarios):\n",
    "                    parameter_df.loc[p,'Parameter Value - S'+str(s+1)]=LCI_df.loc[i,'amount']\n",
    "                parameter_df.loc[p,'Parameter Value - default']=LCI_df.loc[i,'amount']\n",
    "                if LCI_df.loc[i,'material flow'] == True:\n",
    "                    parameter_df.loc[p, 'Group']=foreground_system_groups[LCI_df.loc[i,'activity code']]\n",
    "                p=p+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aa67be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_col_dict={}\n",
    "for c,col in enumerate(parameter_df.columns):\n",
    "    params_col_dict[col]=excel_cols[c]\n",
    "    \n",
    "params_row_dict={}\n",
    "for p,param in enumerate(parameter_df['Parameter-ID']):\n",
    "    params_row_dict[param]=p+2\n",
    "#params_row_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05533e53",
   "metadata": {},
   "source": [
    "#### 2.2.3 LCA calculations for unique exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a389b",
   "metadata": {},
   "source": [
    "**Technosphere**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8a4edb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCI_df_tech=LCI_df[LCI_df['type']=='technosphere']\n",
    "unique_inputs_tech=LCI_df_tech['input code'].unique()\n",
    "unique_activities_tech=LCI_df_tech['activity code'].unique()\n",
    "CF_dict_techno={}\n",
    "\n",
    "for d,db in enumerate(dbs):\n",
    "    functional_units_tech=[]\n",
    "    reference_actcodes_tech=[]\n",
    "\n",
    "    for actcode in unique_inputs_tech:\n",
    "        if actcode not in unique_activities_tech:\n",
    "            reference_actcodes_tech.append(actcode)\n",
    "            functional_unit={db.get(actcode):1}\n",
    "            functional_units_tech.append(functional_unit)\n",
    "        \n",
    "    calculation_setup = {'inv': functional_units_tech, 'ia': LCIA_methods}\n",
    "    bw.calculation_setups['excel tool'] = calculation_setup\n",
    "    mlca = bw.MultiLCA('excel tool')\n",
    "    \n",
    "    CF_dict_techno_db={}\n",
    "\n",
    "    for a,actcode in enumerate(reference_actcodes_tech):\n",
    "        CF_dict_techno_flow={}\n",
    "        for i,IC in enumerate(LCIA_method_names):\n",
    "            CF_dict_techno_flow[IC]=mlca.results[a,i]\n",
    "        CF_dict_techno_db[actcode]=CF_dict_techno_flow\n",
    "    \n",
    "    CF_dict_techno[db_names[d]]=CF_dict_techno_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccadb891",
   "metadata": {},
   "source": [
    "**Biosphere**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b4ab775",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCIA_fp=r\"{}\".format(general_info['LCIA implementation file path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf173c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCIA=pd.read_excel(LCIA_fp,sheet_name='CFs')\n",
    "\n",
    "LCI_df_bio=LCI_df[LCI_df['type']=='biosphere']\n",
    "unique_inputs_bio=LCI_df_bio['input code'].unique()\n",
    "unique_activities_bio=LCI_df_bio['activity code'].unique()\n",
    "\n",
    "functional_units_bio=[]\n",
    "reference_actcodes_bio=[]\n",
    "\n",
    "for actcode in unique_inputs_bio:\n",
    "    if actcode not in unique_activities_bio:\n",
    "        reference_actcodes_bio.append(actcode)\n",
    "        functional_unit={biosphere.get(actcode):1}\n",
    "        functional_units_bio.append(functional_unit)\n",
    "        \n",
    "functional_units=[*functional_units_tech,*functional_units_bio]\n",
    "reference_actcodes=[*reference_actcodes_tech,*reference_actcodes_bio]\n",
    "\n",
    "CF_dfs={}\n",
    "for i,IC in enumerate(LCIA_method_names):\n",
    "    CF_dfs[IC]=LCIA[(LCIA['Method']==LCIA_methods[i][0])&(LCIA['Category']==LCIA_methods[i][1])&(LCIA['Indicator']==LCIA_methods[i][2])]\n",
    "    \n",
    "    \n",
    "CF_dict_bio={}\n",
    "for actcode in reference_actcodes_bio:\n",
    "    bioflow=biosphere.get(actcode)\n",
    "    bioflow_name=bioflow['name']\n",
    "    bioflow_c0=bioflow['categories'][0]\n",
    "    if len(bioflow['categories'])==2:\n",
    "        bioflow_c1=bioflow['categories'][1]\n",
    "    else:\n",
    "        bioflow_c1='unspecified'\n",
    "    CF_dict_bio_bioflow={}\n",
    "    for IC in LCIA_method_names:\n",
    "        CF_df=CF_dfs[IC]\n",
    "        CF_df_filtered=CF_df[(CF_df['Name']==bioflow_name)&(CF_df['Compartment']==bioflow_c0)&(CF_df['Subcompartment']==bioflow_c1)]\n",
    "        if len(CF_df_filtered)==0:\n",
    "            CF=0\n",
    "        else:\n",
    "            CF=CF_df_filtered['CF'].values[0]\n",
    "        CF_dict_bio_bioflow[IC]=CF\n",
    "    CF_dict_bio[actcode]=CF_dict_bio_bioflow    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6ea81",
   "metadata": {},
   "source": [
    "#### 2.2.4 Add characterization factors to LCI-DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6826bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCI_df_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        LCI_df_sheet_names[db+'_'+s]='LCI_'+db+'_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f28779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCI_dbs={}\n",
    "\n",
    "for d,db in enumerate(dbs):\n",
    "    for s in scenarios:\n",
    "        LCI_df_db=LCI_df.copy()\n",
    "\n",
    "        for i in LCI_df_db.index:\n",
    "            input_code=LCI_df_db.loc[i,'input code']\n",
    "            exc_type=LCI_df_db.loc[i,'type']\n",
    "            if exc_type=='biosphere':\n",
    "                for IC in LCIA_method_names:\n",
    "                    LCI_df_db.loc[i,IC]=CF_dict_bio[input_code][IC]\n",
    "            if exc_type=='technosphere':\n",
    "                if input_code in reference_actcodes_tech:\n",
    "                    for IC in LCIA_method_names:\n",
    "                        LCI_df_db.loc[i,IC]=CF_dict_techno[db_names[d]][input_code][IC] \n",
    "                        \n",
    "        LCI_df_db['formula excel']=LCI_df_db['formula']\n",
    "        parameters=parameter_df['Parameter-ID']        \n",
    "            \n",
    "        # Excel formula\n",
    "        for i in LCI_df_db.index:\n",
    "            formula=LCI_df_db.loc[i,'formula']\n",
    "            if type(formula)==str:\n",
    "                formula_new=formula\n",
    "                for p,param in enumerate(reversed(parameters)):\n",
    "                    formula_new=formula_new.replace(param,params_sheet_name+'!'\\\n",
    "                                +params_col_dict['Parameter Value - '+s]+str(params_row_dict[param]))\n",
    "                formula_new='='+formula_new\n",
    "                LCI_df_db.loc[i,'formula excel']=formula_new\n",
    "            else:\n",
    "                LCI_df_db.loc[i,'formula excel']='='+excel_cols[LCI_df_db.columns.get_loc('amount')]\\\n",
    "                                                    +str(i+2)\n",
    "        \n",
    "        for i in LCI_df_db.index:\n",
    "            if LCI_df_db.loc[i,'type']!='production':\n",
    "                for IC in LCIA_method_names:\n",
    "                    LCI_df_db.loc[i,IC+' Impact']='='+excel_cols[LCI_df_db.columns.get_loc('formula excel')]\\\n",
    "                                                        +str(i+2)+'*'\\\n",
    "                                                    +excel_cols[LCI_df_db.columns.get_loc(IC)]+str(i+2)\n",
    "                    \n",
    "        for actcode in LCI_df_db['activity code'].unique():\n",
    "            sub_df=LCI_df_db[LCI_df_db['activity code']==actcode]\n",
    "            for n,IC in enumerate(LCIA_method_names):\n",
    "                formula='='\n",
    "                col=excel_cols[LCI_df_db.columns.get_loc(IC+' Impact')]\n",
    "                for i in sub_df.index[1:]:\n",
    "                    ind=str(i+2)\n",
    "                    formula=formula+'+'+col+ind\n",
    "                LCI_df_db.loc[sub_df.index[0], IC+' Impact']=formula\n",
    "                \n",
    "        LCI_df_db_prod=LCI_df_db[LCI_df_db['type']=='production']\n",
    "        prod_dict={}\n",
    "        \n",
    "        for i in LCI_df_db_prod.index:\n",
    "            actcode=LCI_df_db_prod.loc[i,'activity code']\n",
    "            prod_dict[actcode]=i+2\n",
    "            \n",
    "        for i in LCI_df_db.index:\n",
    "            if LCI_df_db.loc[i,'type']!='production':\n",
    "                input_code=LCI_df_db.loc[i,'input code']\n",
    "                if input_code in prod_dict.keys():\n",
    "                    for n,IC in enumerate(LCIA_method_names):\n",
    "                        col=excel_cols[LCI_df_db.columns.get_loc(IC+' Impact')]\n",
    "                        LCI_df_db.loc[i,IC]='='+col+str(prod_dict[input_code])+'*'\\\n",
    "                                               +excel_cols[LCI_df_db.columns.get_loc('formula excel')]\\\n",
    "                                               +str(prod_dict[input_code])\n",
    "                    \n",
    "        LCI_dbs[db_names[d]+'_'+s]=LCI_df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "81e7efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCI_df_col_dict={}\n",
    "for c,col in enumerate(LCI_df_db.columns):\n",
    "    LCI_df_col_dict[col]=excel_cols[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce580af",
   "metadata": {},
   "source": [
    "#### 2.2.5 LCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "830b4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCA_results_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        LCA_results_sheet_names[db+'_'+s]='LCA_'+db+'_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "74816175",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCA_results={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        LCA_results_db=pd.DataFrame()\n",
    "        actcodes=act_codes\n",
    "        actnames=act_names\n",
    "\n",
    "        for a,actcode in enumerate(actcodes):\n",
    "            LCA_results_db.loc[a,'Pathway']=actnames[a]\n",
    "            for i,IC in enumerate(LCIA_method_names):\n",
    "                col=IC+' Impact'\n",
    "                LCA_results_db.loc[a,IC]='=LCI_'+db+'_'+s+'!'+LCI_df_col_dict[col]+str(prod_dict[actcode])\\\n",
    "                                         +'/LCIA_Methods!D'+str(i+2)\n",
    "\n",
    "        LCA_results[db+'_'+s]=LCA_results_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186e6fd",
   "metadata": {},
   "source": [
    "### 2.3 Perturbation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3f6362fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m LCI_df\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m     37\u001b[0m     act\u001b[38;5;241m=\u001b[39meidb\u001b[38;5;241m.\u001b[39mget(LCI_df\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 38\u001b[0m     exchg\u001b[38;5;241m=\u001b[39m[exc \u001b[38;5;28;01mfor\u001b[39;00m exc \u001b[38;5;129;01min\u001b[39;00m act\u001b[38;5;241m.\u001b[39mexchanges() \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mas_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39mLCI_df\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput code\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     39\u001b[0m     exc_dict[i]\u001b[38;5;241m=\u001b[39mexchg\n\u001b[0;32m     40\u001b[0m exc_dict\n",
      "Cell \u001b[1;32mIn[119], line 38\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m LCI_df\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m     37\u001b[0m     act\u001b[38;5;241m=\u001b[39meidb\u001b[38;5;241m.\u001b[39mget(LCI_df\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 38\u001b[0m     exchg\u001b[38;5;241m=\u001b[39m[exc \u001b[38;5;28;01mfor\u001b[39;00m exc \u001b[38;5;129;01min\u001b[39;00m act\u001b[38;5;241m.\u001b[39mexchanges() \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mexc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[38;5;241m.\u001b[39mas_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39mLCI_df\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput code\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     39\u001b[0m     exc_dict[i]\u001b[38;5;241m=\u001b[39mexchg\n\u001b[0;32m     40\u001b[0m exc_dict\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\bw2data\\proxies.py:151\u001b[0m, in \u001b[0;36mExchangeProxyBase._get_input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidExchange(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing valid data for `input` field\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input \u001b[38;5;241m=\u001b[39m \u001b[43mget_activity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\bw2data\\utils.py:335\u001b[0m, in \u001b[0;36mget_activity\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Database\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnknownObject(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be understood as an activity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or `(database, code)` tuple.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\bw2data\\backends\\peewee\\database.py:132\u001b[0m, in \u001b[0;36mSQLiteBackend.get\u001b[1;34m(self, code)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Activity(\n\u001b[1;32m--> 132\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_queryset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mActivityDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\peewee.py:6970\u001b[0m, in \u001b[0;36mBaseModelSelect.get\u001b[1;34m(self, database)\u001b[0m\n\u001b[0;32m   6968\u001b[0m clone\u001b[38;5;241m.\u001b[39m_cursor_wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6969\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   6971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m   6972\u001b[0m     sql, params \u001b[38;5;241m=\u001b[39m clone\u001b[38;5;241m.\u001b[39msql()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\peewee.py:1918\u001b[0m, in \u001b[0;36mdatabase_required.<locals>.inner\u001b[1;34m(self, database, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m database:\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery must be bound to a database in order \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1917\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto call \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 1918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, database, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\peewee.py:1989\u001b[0m, in \u001b[0;36mBaseQuery.execute\u001b[1;34m(self, database)\u001b[0m\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;129m@database_required\u001b[39m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, database):\n\u001b[1;32m-> 1989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\peewee.py:2162\u001b[0m, in \u001b[0;36mSelectBase._execute\u001b[1;34m(self, database)\u001b[0m\n\u001b[0;32m   2160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, database):\n\u001b[0;32m   2161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor_wrapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2162\u001b[0m         cursor \u001b[38;5;241m=\u001b[39m \u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2163\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor_wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cursor_wrapper(cursor)\n\u001b[0;32m   2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor_wrapper\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\peewee.py:3190\u001b[0m, in \u001b[0;36mDatabase.execute\u001b[1;34m(self, query, commit, **context_options)\u001b[0m\n\u001b[0;32m   3188\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sql_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext_options)\n\u001b[0;32m   3189\u001b[0m sql, params \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39msql(query)\u001b[38;5;241m.\u001b[39mquery()\n\u001b[1;32m-> 3190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\peewee.py:3177\u001b[0m, in \u001b[0;36mDatabase.execute_sql\u001b[1;34m(self, sql, params, commit)\u001b[0m\n\u001b[0;32m   3175\u001b[0m cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor(commit)\n\u001b[0;32m   3176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3177\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   3179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautorollback \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_transaction():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if general_info['Conduct perturbation analysis'] == 'yes':\n",
    "\n",
    "    default_values={}\n",
    "    for i in parameter_df.index:\n",
    "        default_values[parameter_df.loc[i,'Parameter-ID']]=parameter_df.loc[i,'Parameter Value - default']\n",
    "\n",
    "    perturbation_runs={}\n",
    "    for r in parameter_df.index:\n",
    "        run='run'+str(r+1)\n",
    "        run_params={}\n",
    "        for i in parameter_df.index:\n",
    "            if i!=r:\n",
    "                run_params[parameter_df.loc[i,'Parameter-ID']]=parameter_df.loc[i,'Parameter Value - default']\n",
    "            else:\n",
    "                run_params[parameter_df.loc[i,'Parameter-ID']]=parameter_df.loc[i,'Parameter Value - default']*1.001\n",
    "        perturbation_runs[run]=run_params\n",
    "\n",
    "    relevant_indices_runs={}\n",
    "    for run in perturbation_runs.keys():\n",
    "        relevant_indices={}\n",
    "        for i in LCI_df_db.index:\n",
    "            formula=LCI_df_db.loc[i,'formula']\n",
    "            if type(formula)==str:\n",
    "                evaluated_formula=formula\n",
    "                for p,param in enumerate(reversed(perturbation_runs[run].keys())):\n",
    "                    evaluated_formula=evaluated_formula.replace(param,str(perturbation_runs[run][param]))\n",
    "                evaluated_formula=evaluated_formula.replace('amount', str(LCI_df_db.loc[i,'amount']))\n",
    "                evaluated_formula=float(eval(evaluated_formula))\n",
    "                if LCI_df_db.loc[i,'amount']!=evaluated_formula:\n",
    "                    relevant_indices[i]=evaluated_formula\n",
    "                    #print(run,i,evaluated_formula)\n",
    "        relevant_indices_runs[run]=relevant_indices\n",
    "    relevant_indices_runs\n",
    "\n",
    "    exc_dict={}\n",
    "    for i in LCI_df.index:\n",
    "        act=eidb.get(LCI_df.loc[i,'activity code'])\n",
    "        exchg=[exc for exc in act.exchanges() if exc.input.as_dict()['code'] ==LCI_df.loc[i,'input code']][0]\n",
    "        exc_dict[i]=exchg\n",
    "    exc_dict\n",
    "\n",
    "    perturbation_df=pd.DataFrame()\n",
    "\n",
    "    wg=eidb.get(WasteGen_code)\n",
    "    \n",
    "    non_stochastic_lca=bw.LCA({wg:1})\n",
    "    non_stochastic_lca.lci()\n",
    "    C_matrices={}\n",
    "    for i,method in enumerate(LCIA_methods):\n",
    "        non_stochastic_lca.switch_method(method)\n",
    "        C_matrices[LCIA_method_names[i]] = non_stochastic_lca.characterization_matrix\n",
    "    \n",
    "    for r,run in enumerate(perturbation_runs.keys()):\n",
    "        print(run)\n",
    "        if run == 'run1':\n",
    "            lca = bw.LCA({wg:1.001})   \n",
    "\n",
    "        else:\n",
    "            for ind in relevant_indices_runs[run].keys():\n",
    "                default_amount=LCI_df.loc[ind,'amount']\n",
    "                exc_dict[ind]['amount']=relevant_indices_runs[run][ind]\n",
    "                exc_dict[ind].save()\n",
    "\n",
    "            lca = bw.LCA({wg:1})          \n",
    "\n",
    "        lca.lci()\n",
    "        for IC in LCIA_method_names:\n",
    "            perturbation_df.loc['P'+str(r),IC]=(C_matrices[IC]*lca.inventory).sum()\n",
    "\n",
    "        if run != 'run1':\n",
    "            for ind in relevant_indices_runs[run].keys():\n",
    "                default_amount=LCI_df.loc[ind,'amount']\n",
    "                exc_dict[ind]['amount']=default_amount\n",
    "                exc_dict[ind].save()        \n",
    "\n",
    "    # calculation of sensitivity ratios\n",
    "    calculation_setup = {'inv': [{wg:1}], 'ia': LCIA_methods}\n",
    "    bw.calculation_setups['perturbation'] = calculation_setup\n",
    "    default_mlca = bw.MultiLCA('perturbation')       \n",
    "\n",
    "    senstivity_ratio_df=pd.DataFrame()\n",
    "\n",
    "    for i,ind in enumerate(perturbation_df.index):\n",
    "        for c,col in enumerate(perturbation_df.columns):\n",
    "            delta_rel_lca=(perturbation_df.loc[ind,col]-default_mlca.results[0][c])/default_mlca.results[0][c]\n",
    "            delta_rel_param=1.001\n",
    "            senstivity_ratio_df.loc[ind,col]=delta_rel_lca/delta_rel_param\n",
    "\n",
    "    senstivity_ratio_df=senstivity_ratio_df.reset_index(drop=True)\n",
    "\n",
    "    parameter_df=pd.concat([parameter_df, senstivity_ratio_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f56b74",
   "metadata": {},
   "source": [
    "### 2.4 Waste Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ad5da437",
   "metadata": {},
   "outputs": [],
   "source": [
    "Waste_Comp_sheet_names={}\n",
    "\n",
    "for s in scenarios:\n",
    "    Waste_Comp_sheet_names[s]='Waste_Composition_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f3c9209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PW1</th>\n",
       "      <th>PW2</th>\n",
       "      <th>PW3</th>\n",
       "      <th>PW4</th>\n",
       "      <th>PW5</th>\n",
       "      <th>PW6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PP</th>\n",
       "      <td>=ABS(LCI_default_default!AB2247)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2252)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2258)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2262)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2269)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2276)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>=ABS(LCI_default_default!AB2259)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2265)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2272)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2279)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>=ABS(LCI_default_default!AB2254)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2265)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2272)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2279)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Films</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>=ABS(LCI_default_default!AB2255)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2266)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2273)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PET</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>=ABS(LCI_default_default!AB2257)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2263)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2270)</td>\n",
       "      <td>=ABS(LCI_default_default!AB2277)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PW1                               PW2  \\\n",
       "PP     =ABS(LCI_default_default!AB2247)  =ABS(LCI_default_default!AB2252)   \n",
       "PS                                  NaN                               NaN   \n",
       "EPS                                 NaN                               NaN   \n",
       "Films                               NaN                               NaN   \n",
       "PET                                 NaN                               NaN   \n",
       "\n",
       "                                    PW3                               PW4  \\\n",
       "PP     =ABS(LCI_default_default!AB2258)  =ABS(LCI_default_default!AB2262)   \n",
       "PS     =ABS(LCI_default_default!AB2259)  =ABS(LCI_default_default!AB2265)   \n",
       "EPS    =ABS(LCI_default_default!AB2254)  =ABS(LCI_default_default!AB2265)   \n",
       "Films  =ABS(LCI_default_default!AB2255)  =ABS(LCI_default_default!AB2266)   \n",
       "PET    =ABS(LCI_default_default!AB2257)  =ABS(LCI_default_default!AB2263)   \n",
       "\n",
       "                                    PW5                               PW6  \n",
       "PP     =ABS(LCI_default_default!AB2269)  =ABS(LCI_default_default!AB2276)  \n",
       "PS     =ABS(LCI_default_default!AB2272)  =ABS(LCI_default_default!AB2279)  \n",
       "EPS    =ABS(LCI_default_default!AB2272)  =ABS(LCI_default_default!AB2279)  \n",
       "Films  =ABS(LCI_default_default!AB2273)  =ABS(LCI_default_default!AB2280)  \n",
       "PET    =ABS(LCI_default_default!AB2270)  =ABS(LCI_default_default!AB2277)  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Waste_Comp_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a15a4040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PE-HD', 'PP', 'PET', 'PS', 'EPS', 'Films']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "material_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4233a8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>input code</th>\n",
       "      <th>input unit</th>\n",
       "      <th>input location</th>\n",
       "      <th>activity</th>\n",
       "      <th>activity code</th>\n",
       "      <th>activity location</th>\n",
       "      <th>amount</th>\n",
       "      <th>type</th>\n",
       "      <th>material flow</th>\n",
       "      <th>formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>production</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>treatment of plastic waste as part of the resi...</td>\n",
       "      <td>Residual-Waste-HDPE-MBT</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.114244</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>True</td>\n",
       "      <td>P340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>treatment of plastic waste as part of the resi...</td>\n",
       "      <td>Residual-Waste-PP-MBT</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.117164</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>True</td>\n",
       "      <td>P341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>treatment of plastic waste as part of the resi...</td>\n",
       "      <td>Residual-Waste-PET-MBT</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.154618</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>True</td>\n",
       "      <td>P342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>treatment of plastic waste as part of the resi...</td>\n",
       "      <td>Residual-Waste-PS-MBT</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>True</td>\n",
       "      <td>P343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>treatment of plastic waste as part of the resi...</td>\n",
       "      <td>Residual-Waste-EPS-MBT</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>True</td>\n",
       "      <td>P344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>treatment of plastic waste as part of the resi...</td>\n",
       "      <td>Residual-Waste-Films-MBT</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>DE</td>\n",
       "      <td>treatment of residual waste, MBT</td>\n",
       "      <td>TP_RW_MBT</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.602341</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>True</td>\n",
       "      <td>P345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "2272                   treatment of residual waste, MBT   \n",
       "2273  treatment of plastic waste as part of the resi...   \n",
       "2274  treatment of plastic waste as part of the resi...   \n",
       "2275  treatment of plastic waste as part of the resi...   \n",
       "2276  treatment of plastic waste as part of the resi...   \n",
       "2277  treatment of plastic waste as part of the resi...   \n",
       "2278  treatment of plastic waste as part of the resi...   \n",
       "\n",
       "                    input code input unit input location  \\\n",
       "2272                 TP_RW_MBT   kilogram             DE   \n",
       "2273   Residual-Waste-HDPE-MBT   kilogram             DE   \n",
       "2274     Residual-Waste-PP-MBT   kilogram             DE   \n",
       "2275    Residual-Waste-PET-MBT   kilogram             DE   \n",
       "2276     Residual-Waste-PS-MBT   kilogram             DE   \n",
       "2277    Residual-Waste-EPS-MBT   kilogram             DE   \n",
       "2278  Residual-Waste-Films-MBT   kilogram             DE   \n",
       "\n",
       "                              activity activity code activity location  \\\n",
       "2272  treatment of residual waste, MBT     TP_RW_MBT                DE   \n",
       "2273  treatment of residual waste, MBT     TP_RW_MBT                DE   \n",
       "2274  treatment of residual waste, MBT     TP_RW_MBT                DE   \n",
       "2275  treatment of residual waste, MBT     TP_RW_MBT                DE   \n",
       "2276  treatment of residual waste, MBT     TP_RW_MBT                DE   \n",
       "2277  treatment of residual waste, MBT     TP_RW_MBT                DE   \n",
       "2278  treatment of residual waste, MBT     TP_RW_MBT                DE   \n",
       "\n",
       "        amount          type material flow formula  \n",
       "2272  1.000000    production         False     NaN  \n",
       "2273  0.114244  technosphere          True    P340  \n",
       "2274  0.117164  technosphere          True    P341  \n",
       "2275  0.154618  technosphere          True    P342  \n",
       "2276  0.005816  technosphere          True    P343  \n",
       "2277  0.005816  technosphere          True    P344  \n",
       "2278  0.602341  technosphere          True    P345  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b8b17d29",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PE-HD'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m mat \u001b[38;5;129;01min\u001b[39;00m sub_df\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput code\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     10\u001b[0m                 Waste_Comp_S\u001b[38;5;241m.\u001b[39mloc[mat,actname]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=ABS(LCI_default_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mLCI_df_col_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula excel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m    \n\u001b[1;32m---> 11\u001b[0m Waste_Comp_S\u001b[38;5;241m=\u001b[39m\u001b[43mWaste_Comp_S\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmaterial_codes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m Waste_Comp[s]\u001b[38;5;241m=\u001b[39mWaste_Comp_S\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MoEWe2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PE-HD'] not in index\""
     ]
    }
   ],
   "source": [
    "Waste_Comp={}\n",
    "\n",
    "for s in scenarios:\n",
    "    Waste_Comp_S=pd.DataFrame()\n",
    "    for a,actname in enumerate(Pathway_names):\n",
    "        sub_df=LCI_df[LCI_df['activity code']==Pathway_codes[a]]\n",
    "        for i in sub_df.index:\n",
    "            for mat in material_codes:\n",
    "                if mat in sub_df.loc[i,'input code']:\n",
    "                    Waste_Comp_S.loc[mat,actname]='=ABS(LCI_default_'+s+'!'+LCI_df_col_dict['formula excel']+str(i+2)+')'    \n",
    "    Waste_Comp_S=Waste_Comp_S.loc[material_codes]\n",
    "    Waste_Comp[s]=Waste_Comp_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90130932",
   "metadata": {},
   "outputs": [],
   "source": [
    "Waste_Comp_col_dict={}\n",
    "for c,col in enumerate(Waste_Comp_S.columns):\n",
    "    Waste_Comp_col_dict[col]=excel_cols[c+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a3c8f",
   "metadata": {},
   "source": [
    "### 2.5 Waste Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1942b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Waste_Gen_sheet_names={}\n",
    "\n",
    "for s in scenarios:\n",
    "    Waste_Gen_sheet_names[s]='Waste_Generation_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8402988",
   "metadata": {},
   "outputs": [],
   "source": [
    "Waste_Gen={}\n",
    "\n",
    "for s in scenarios:\n",
    "    Waste_Gen_S=pd.DataFrame(index=act_names)\n",
    "    name_code_dict={}\n",
    "    for a,ac in enumerate(Pathway_codes):\n",
    "        name_code_dict[Pathway_names[a]]=ac\n",
    "\n",
    "    sub_df=LCI_df[LCI_df['activity code']==WasteGen_code]\n",
    "    for i in sub_df.index:\n",
    "        for a,ac in enumerate(Pathway_codes):\n",
    "            if ac == sub_df.loc[i,'input code']:\n",
    "                Waste_Gen_S.loc[Pathway_names[a],'relative']='=ABS(LCI_default_'+s+'!'\\\n",
    "                                                        +LCI_df_col_dict['formula excel']+str(i+2)+')'\n",
    "                Waste_Gen_S.loc[Pathway_names[a],'absolute [kg]']='=ABS(LCI_default_'+s+'!'\\\n",
    "                                                +LCI_df_col_dict['formula excel']+str(i+2)+'*'\\\n",
    "                                                +\"HLOOKUP(\\\"Parameter Value - \"+s+\"\\\",Parameter!C1:\"\\\n",
    "                                                +excel_cols[n_scenarios+2]+\"2,2,FALSE))\"\n",
    "    #Waste_Gen_S=Waste_Gen_S.sort_index()\n",
    "    for c,col in enumerate(Waste_Gen_S.columns):\n",
    "        Waste_Gen_S.loc[act_names[0],col]='=SUM('+excel_cols[c+1]+str(3)+':'+excel_cols[c+1]+str(len(Waste_Gen_S)+1)+')'\n",
    "    \n",
    "    Waste_Gen[s]=Waste_Gen_S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc724380",
   "metadata": {},
   "source": [
    "### 2.6 Original Environmental Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b55fb0",
   "metadata": {},
   "source": [
    "#### 2.6.1 Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f87529",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_df=pd.read_excel(\"ExcelTool_GeneratorInput_Template.xlsx\", index_col=0, sheet_name='EnvironmentalValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OEV_material_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    OEV_material_sheet_names[db]='OEV_materials_'+db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "material_dict={}\n",
    "material_dict_db={}\n",
    "\n",
    "for d,db in enumerate(dbs):\n",
    "    for i in EV_df.index:\n",
    "        material_dict_db[i]=[act for act in db if act['name']==EV_df.loc[i,'Material activity name']\n",
    "                            and act['unit']==EV_df.loc[i,'Material activity unit']\n",
    "                            and act['location']==EV_df.loc[i,'Material activity location']][0]\n",
    "    material_dict[db_names[d]]=material_dict_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5147ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OEV_materials={}\n",
    "\n",
    "for d,db in enumerate(db_names):\n",
    "    functional_units=[]\n",
    "    for act in material_dict[db].values():\n",
    "        functional_units.append({act:1})\n",
    "    functional_units\n",
    "\n",
    "    calculation_setup = {'inv': functional_units, 'ia': LCIA_methods}\n",
    "\n",
    "    bw.calculation_setups['materials'] = calculation_setup\n",
    "\n",
    "    mlca = bw.MultiLCA('materials')\n",
    "\n",
    "    OEV_material_norm=np.empty(np.shape(mlca.results))\n",
    "\n",
    "    for f,fu in enumerate(functional_units):\n",
    "        OEV_material_norm[f]=mlca.results[f]/nfs\n",
    "\n",
    "    OEV_materials_db=pd.DataFrame(OEV_material_norm, \n",
    "                 index=EV_df.index,\n",
    "                 columns=LCIA_method_names)\n",
    "\n",
    "    OEV_materials[db]=OEV_materials_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "OEV_materials_col_dict={}\n",
    "for c,col in enumerate(OEV_materials[db].columns):\n",
    "    OEV_materials_col_dict[col]=excel_cols[c+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb16566",
   "metadata": {},
   "source": [
    "#### 2.6.2 Treatment Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OEV_Pathways_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        OEV_Pathways_sheet_names[db+'_'+s]='OEV_Pathways_'+db+'_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OEV_Pathways={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        OEV_Pathways_db=pd.DataFrame(index=act_names)\n",
    "        actnames=Pathway_names\n",
    "\n",
    "        for Pathway in actnames:\n",
    "            for n,IC in enumerate(LCIA_method_names):\n",
    "                OEV_Pathways_db.loc[Pathway,IC]='=SUMPRODUCT('+OEV_material_sheet_names[db]+'!'+OEV_materials_col_dict[IC]+'2:'+\\\n",
    "                                    OEV_material_sheet_names[db]+'!'+OEV_materials_col_dict[IC]+str(len(EV_df.index)+1)+','+ \\\n",
    "                                    Waste_Comp_sheet_names[s]+'!'+Waste_Comp_col_dict[Pathway]+'2:'+\\\n",
    "                                    Waste_Comp_sheet_names[s]+'!'+Waste_Comp_col_dict[Pathway]+str(len(EV_df.index)+1) \\\n",
    "                                    +')'\n",
    "    \n",
    "        for i,IC in enumerate(LCIA_method_names):\n",
    "            OEV_Pathways_db.loc[act_names[0],IC]='=SUMPRODUCT('+Waste_Gen_sheet_names[s]+'!B3:'+Waste_Gen_sheet_names[s]+'!B'+str(len(actnames)+2)+','\\\n",
    "                                            +excel_cols[i+1]+str(3)+':'+excel_cols[i+1]+str(len(actnames)+2)+')'\n",
    "\n",
    "        OEV_Pathways[db+'_'+s]=OEV_Pathways_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45719d20",
   "metadata": {},
   "source": [
    "### 2.7 Environmental Waste Utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64cbfd",
   "metadata": {},
   "source": [
    "#### 2.7.1 Per Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indicator_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        Indicator_sheet_names[db+'_'+s]='Indicator_'+db+'_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indicator={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        Indicator_db=pd.DataFrame(index=OEV_Pathways_db.index,columns=OEV_Pathways_db.columns)\n",
    "\n",
    "        for i,ind in enumerate(Indicator_db.index):\n",
    "            for c,col in enumerate(Indicator_db.columns):\n",
    "                Indicator_db.loc[ind,col]='=-'+LCA_results_sheet_names[db+'_'+s]+'!'\\\n",
    "                +excel_cols[c+1]+str(i+2)+'/'+OEV_Pathways_sheet_names[db+'_'+s]+'!'+excel_cols[c+1]+str(i+2)\n",
    "        \n",
    "        Indicator[db+'_'+s]=Indicator_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c4ec5",
   "metadata": {},
   "source": [
    "#### 2.7.2 Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted_Indicator_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        Weighted_Indicator_sheet_names[db+'_'+s]='W_Ind_'+db+'_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a676dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted_Indicator={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        Weighted_Indicator_db=pd.DataFrame()\n",
    "\n",
    "        for a,act in enumerate(Indicator_db.index):\n",
    "            for w,wm in enumerate(Weighting.columns):\n",
    "                formula='='\n",
    "                for i,IC in enumerate(LCIA_method_names):\n",
    "                    formula=formula+'+'+Indicator_sheet_names[db+'_'+s]+'!'+excel_cols[i+1]+str(a+2)\\\n",
    "                            +'*'+Weighting_sheet_name+'!'+excel_cols[w+1]+str(i+2)\n",
    "                Weighted_Indicator_db.loc[act,wm]=formula\n",
    "        Weighted_Indicator[db+'_'+s]=Weighted_Indicator_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a457e0",
   "metadata": {},
   "source": [
    "### 2.8 Supply Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_chain_sheet_names={}\n",
    "\n",
    "for s in scenarios:\n",
    "    for act in act_names:\n",
    "        supply_chain_sheet_names[s+'_'+act]='supply_chain_'+s+'_'+act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee26314",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCI=LCI_dbs[db_names[0]+'_'+scenarios[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supply_chain_per_Pathway(LCI,\n",
    "                       activity_df,\n",
    "                       supply_chain_df,\n",
    "                       db, scenario, n_scenarios, \n",
    "                       amount_col=None,\n",
    "                       excel_cols=excel_cols,\n",
    "                       previous_input_code=None, \n",
    "                       previous_input_name=None,\n",
    "                       first=True, x=None):\n",
    "    if first == True:\n",
    "        x=1\n",
    "        amount_col=excel_cols[LCI.columns.get_loc('formula excel')]\n",
    "        reference_amount=\"=VLOOKUP(\\\"\"+previous_input_name+\"\\\",Waste_Generation_\"+scenario+\"!A1:C100,3,FALSE)*\" \\\n",
    "                            +str(LCI[(LCI['type']=='production')&(LCI['input code']==previous_input_code)]['amount'].iloc[0])\n",
    "        supply_chain_df.loc[previous_input_code,'amount']=reference_amount\n",
    "        \n",
    "    if previous_input_code not in LCI['activity code'].unique():\n",
    "        return\n",
    "    else:\n",
    "        if x ==1000:\n",
    "            return\n",
    "        else:\n",
    "            x=x+1\n",
    "            ref=LCI[LCI['activity code']==previous_input_code]\n",
    "            previous_index=supply_chain_df.index.get_loc(previous_input_code)+2\n",
    "            production_index=ref[(ref['input code']==previous_input_code)&(ref['type']=='production')].index[0]+2\n",
    "            for i in ref.index:\n",
    "                if ref.loc[i,'type']!='production':\n",
    "                    input_code=ref.loc[i,'input code']\n",
    "                    if len(LCI[(LCI['input code']==input_code)&(LCI['type']=='production')])>0:\n",
    "                        act_index=LCI[(LCI['input code']==input_code)&(LCI['type']=='production')].index[0]+2\n",
    "                    else:\n",
    "                        act_index=LCI[(LCI['input code']==input_code)].index[0]+2\n",
    "                    if pd.isnull(supply_chain_df.loc[input_code,'amount'])==True:\n",
    "                        supply_chain_df.loc[input_code,'amount']='=B'+str(previous_index)+'*'+'LCI_'+db+'_'+scenario+'!'\\\n",
    "                                                                +amount_col+str(i+2)+'*'+'LCI_'+db+'_'+scenario+'!'\\\n",
    "                                                                +amount_col+str(production_index)\n",
    "                    else:\n",
    "                        supply_chain_df.loc[input_code,'amount']=supply_chain_df.loc[input_code,'amount']+'+B'\\\n",
    "                                                                +str(previous_index)+'*'+'LCI_'+db+'_'+scenario+'!'\\\n",
    "                                                                +amount_col+str(i+2)+'*'+'LCI_'+db+'_'+scenario+'!'\\\n",
    "                                                                +amount_col+str(production_index)\n",
    "                    previous_input_code=input_code\n",
    "                    supply_chain_per_Pathway(LCI=LCI,\n",
    "                                       activity_df=activity_df,\n",
    "                                       supply_chain_df=supply_chain_df,\n",
    "                                       db=db, scenario=scenario, n_scenarios=n_scenarios, \n",
    "                                       amount_col=amount_col,\n",
    "                                       excel_cols=excel_cols,\n",
    "                                       previous_input_code=previous_input_code, \n",
    "                                       first=False,x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_chain={}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for a,actcode in enumerate(act_codes):\n",
    "        #print(scenario+'_'+act_names[a], actcode)\n",
    "        supply_chain_df=pd.DataFrame(index=LCI['input code'].unique())\n",
    "\n",
    "        supply_chain_per_Pathway(LCI,\n",
    "                       activity_df, \n",
    "                       supply_chain_df,\n",
    "                       db, scenario, n_scenarios,\n",
    "                       previous_input_code=actcode,\n",
    "                       previous_input_name=act_names[a])\n",
    "\n",
    "        supply_chain_df=supply_chain_df.replace(np.nan,0)\n",
    "\n",
    "        supply_chain[scenario+'_'+act_names[a]]=supply_chain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1589b",
   "metadata": {},
   "source": [
    "### 2.9 Contribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf5fc9",
   "metadata": {},
   "source": [
    "#### 2.9.1 Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53db82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_Pathways_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        CA_Pathways_sheet_names[db+'_'+s]='CA_Pathways_'+db+'_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdcd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_Pathways={}\n",
    "amount_col=excel_cols[LCI_df_db.columns.get_loc('formula excel')]\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        CA_Pathways_db=pd.DataFrame(index=OEV_Pathways_db.index, columns=LCIA_method_names)\n",
    "\n",
    "        for n,IC in enumerate(CA_Pathways_db.columns):\n",
    "            for i,ind in enumerate(CA_Pathways_db.index):\n",
    "                 CA_Pathways_db.loc[ind,IC]='='+LCA_results_sheet_names[db+'_'+s]+'!'+excel_cols[n+1]\\\n",
    "                                    +str(i+2)+'*'+Waste_Gen_sheet_names[s]+'!C'+str(i+2)\n",
    "\n",
    "        CA_Pathways[db+'_'+s]=CA_Pathways_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6100641",
   "metadata": {},
   "source": [
    "#### 2.9.2 Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19bb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_acts_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        CA_acts_sheet_names[db+'_'+s]='CA_acts_'+db+'_'+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d9db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity tags\n",
    "activity_tag_dict={}\n",
    "\n",
    "for tag in activity_df['Activity tag'].unique():\n",
    "    if pd.isnull(tag)==False:\n",
    "        tag_list=[]\n",
    "        sub_df=activity_df[activity_df['Activity tag']==tag]\n",
    "        for i in sub_df.index:\n",
    "            sub_dict={}\n",
    "            sub_dict['name']=activity_df.loc[i,'Activity name']\n",
    "            sub_dict['unit']=activity_df.loc[i,'Unit']\n",
    "            sub_dict['location']=activity_df.loc[i,'Location']\n",
    "            tag_list.append(sub_dict)\n",
    "        activity_tag_dict[tag]=tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7bcea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=LCI_dbs['default_default']\n",
    "db='default'\n",
    "scenario='default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in activity_tag_dict.keys():\n",
    "    for tag_act in activity_tag_dict[tag]:\n",
    "        name=tag_act['name']\n",
    "        location=tag_act['location']\n",
    "        unit=tag_act['unit']\n",
    "        for i in df.index:\n",
    "            if (df.loc[i,'input']==name)&(df.loc[i,'input location']==location)&(df.loc[i,'input unit']==unit):\n",
    "                df.loc[i,'activity tag']=tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2203d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in db_names:\n",
    "    for scenario in scenarios:\n",
    "        for tag in activity_tag_dict.keys():\n",
    "            for tag_act in activity_tag_dict[tag]:\n",
    "                if len(df[(df['activity']==tag_act['name'])&(df['type']=='production')])>0:\n",
    "                    for i in df[(df['activity']==tag_act['name'])&(df['type']=='production')].index:\n",
    "                        sub_dict={}\n",
    "                        sub=df[(df['activity']==tag_act['name'])&(df['activity location']==tag_act['location'])]\n",
    "                        index=sub[(sub['activity tag'].isnull()==False)&(sub['type']=='production')].index[0]\n",
    "                        sub_tags=sub[(sub['activity tag'].isnull()==False)&(sub['type']!='production')].index\n",
    "                        tag_act['sub_tags']=sub_tags\n",
    "                        ref_amount= LCI_df_col_dict['formula excel']+str(index+2)\n",
    "                else:\n",
    "                    index=df[(df['input']==tag_act['name'])].index[0]\n",
    "                    ref_amount= LCI_df_col_dict['formula excel']+str(index+2)\n",
    "                tag_act['index']=index\n",
    "                tag_act['ref_amount']=ref_amount\n",
    "                code=df.loc[index,'input code']\n",
    "                tag_act['code']=code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_acts={}\n",
    "\n",
    "for db in db_names:\n",
    "    for scenario in scenarios:\n",
    "        CA_acts_df=pd.DataFrame()\n",
    "        for tag in activity_tag_dict:\n",
    "            for i,IC in enumerate(LCIA_method_names):\n",
    "                unit_impact='('\n",
    "                \n",
    "                for t,tag_act in enumerate(activity_tag_dict[tag]):\n",
    "                    if t != 0:\n",
    "                        unit_impact=unit_impact+'+'\n",
    "                    unit_impact=unit_impact+supply_chain_sheet_names[scenario+'_'+act_names[0]]+'!B'\\\n",
    "                                    +str(supply_chain_df.index.get_loc(tag_act['code'])+2)+'*'+'('+'LCI_'+db+'_'+scenario+'!'+LCI_df_col_dict[IC+' Impact']\\\n",
    "                                    +str(tag_act['index']+2)\n",
    "                    if 'sub_tags' in tag_act.keys():\n",
    "                        for sub_tag in tag_act['sub_tags']:\n",
    "                            unit_impact=unit_impact+'-LCI_'+db+'_'+scenario+'!'+LCI_df_col_dict[IC+' Impact']\\\n",
    "                                        +str(sub_tag+2)\n",
    "                    unit_impact=unit_impact+')'+'/'+'LCI_'+db+'_'+scenario+'!'+tag_act['ref_amount']\n",
    "\n",
    "                CA_acts_df.loc[tag,IC]='='+unit_impact+')'+'/LCIA_Methods!D'+str(i+2)\n",
    "        CA_acts[db+'_'+scenario]=CA_acts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tags=len(activity_tag_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5459660",
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in db_names:\n",
    "    for scenario in scenarios:\n",
    "        CA_acts_df=CA_acts[db+'_'+scenario]\n",
    "        for i,IC in enumerate(LCIA_method_names):\n",
    "            col=excel_cols[i+1]\n",
    "            reference_amount='ABS('+supply_chain_sheet_names[scenario+'_'+act_names[0]]+'!B'\\\n",
    "                                    +str(supply_chain_df.index.get_loc(WasteGen_code)+2)+')'\n",
    "            CA_acts_df.loc['Others', IC]='=LCA_'+db+'_'+scenario+'!'+col+'2*'+reference_amount+'-SUM('+col+'2:'\\\n",
    "                                        +col+str(n_tags+1)+')'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4152f882",
   "metadata": {},
   "source": [
    "### 2.10 EWU-Components: Treatment - Utilization - Material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9af42",
   "metadata": {},
   "source": [
    "#### 2.10.1 Per Impact Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUM_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        for TUM_type in ['Treatm', 'Util', 'Mat']:\n",
    "            TUM_sheet_names[db+'_'+s+'_'+TUM_type]='TUM_'+db+'_'+s+'_'+TUM_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_indices={}\n",
    "LCI_indices={}\n",
    "for wuc in waste_utilization_codes:\n",
    "    sc_indices[wuc]=str(supply_chain_df.index.get_loc(wuc)+2)\n",
    "    LCI_indices[wuc]=str(LCI[LCI['input code']==wuc].index[0]+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc142b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUM={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        for TUM_type in ['Treatm', 'Util', 'Mat']:\n",
    "            TUM_df=pd.DataFrame(index=act_names, columns=LCIA_method_names)\n",
    "            if TUM_type == 'Util':\n",
    "                for act in TUM_df.index:\n",
    "                    for i,IC in enumerate(LCIA_method_names):\n",
    "                        formula='='\n",
    "                        for wuc in waste_utilization_codes:\n",
    "                            formula = formula + '+(supply_chain_'+scenario+'_'+act+'!B'+sc_indices[wuc]+'*'+'LCI_'+db+'_'+scenario+'!'+LCI_df_col_dict[IC+' Impact']\\\n",
    "                                                    +LCI_indices[wuc]+'/'+'LCI_'+db+'_'+scenario+'!AB'+LCI_indices[wuc]+')'                   \n",
    "                        TUM_df.loc[act, IC]=formula+'/LCIA_Methods!D'+str(i+2)\n",
    "                TUM[db+'_'+s+'_'+'Util']=TUM_df\n",
    "            if TUM_type == 'Treatm':\n",
    "                for a,act in enumerate(TUM_df.index):\n",
    "                    for i,IC in enumerate(LCIA_method_names):\n",
    "                        TUM_df.loc[act, IC]='=CA_Pathways_'+db+'_'+s+'!'+excel_cols[i+1]+str(a+2)+\\\n",
    "                                            '-TUM_'+db+'_'+s+'_'+'Util'+'!'+excel_cols[i+1]+str(a+2)\n",
    "                TUM[db+'_'+s+'_'+'Treatm']=TUM_df\n",
    "            if TUM_type == 'Mat':\n",
    "                for a,act in enumerate(TUM_df.index):\n",
    "                    for i,IC in enumerate(LCIA_method_names):\n",
    "                        TUM_df.loc[act, IC]='=OEV_Pathways_'+db+'_'+s+'!'+excel_cols[i+1]+str(a+2)+\"*VLOOKUP(\\\"\"+act+\"\\\",Waste_Generation_\"+scenario+\"!A1:C100,3,FALSE)\"\n",
    "                TUM[db+'_'+s+'_'+'Mat']=TUM_df                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236d632",
   "metadata": {},
   "source": [
    "#### 2.10.2 Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted_TUM_sheet_names={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        for TUM_type in ['Treatm', 'Util', 'Mat']:\n",
    "            Weighted_TUM_sheet_names[db+'_'+s+'_'+TUM_type]='WTUM_'+db+'_'+s+'_'+TUM_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted_TUM={}\n",
    "\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        for TUM_type in ['Treatm', 'Util', 'Mat']:\n",
    "            Weighted_TUM_df=pd.DataFrame()\n",
    "\n",
    "            for a,act in enumerate(TUM_df.index):\n",
    "                for w,wm in enumerate(Weighting.columns):\n",
    "                    formula='='\n",
    "                    for i,IC in enumerate(LCIA_method_names):\n",
    "                        formula=formula+'+'+TUM_sheet_names[db+'_'+s+'_'+TUM_type]+'!'+excel_cols[i+1]+str(a+2)\\\n",
    "                                +'*'+Weighting_sheet_name+'!'+excel_cols[w+1]+str(i+2)\n",
    "                    Weighted_TUM_df.loc[act,wm]=formula\n",
    "            Weighted_TUM[db+'_'+s+'_'+TUM_type]=Weighted_TUM_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c8c7f",
   "metadata": {},
   "source": [
    "### 2.11 Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151da685",
   "metadata": {},
   "source": [
    "#### 2.11.1 Figure 1: Indicator Scores per Impact Category (Spider Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6603e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1_sheet_name='Figure1_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc06c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1_index='=EWU_Dashboard!B3' #selected treatment path / system\n",
    "figure1_df=pd.DataFrame(columns=LCIA_method_names)\n",
    "for i,IC in enumerate(LCIA_method_names):\n",
    "    for a,act in enumerate(act_names):\n",
    "        figure1_df.loc[act,IC]=\"=IF(EWU_Dashboard!B3=A\"+str(a+2)+\",INDIRECT(\\\"\\'\\\"&\"+\\\n",
    "                                            excel_cols[i+1]+str(len(act_names)+2)+\\\n",
    "                                            \"&\\\"\\'!\"+excel_cols[i+1]\\\n",
    "                                            +\"\\\"&VLOOKUP(EWU_Dashboard!B3,dict!A2:B100,2,FALSE)),#N/A)\"\n",
    "    figure1_df.loc['sheet_name',IC]=\"=\\\"Indicator_\\\"&\"+excel_cols[i+1]+str(len(act_names)+3)\\\n",
    "                                        +\"&\\\"_\\\"&EWU_Dashboard!B5\"\n",
    "    figure1_df.loc['db_short',IC]=\"=VLOOKUP(EWU_Dashboard!B4,dict!A2:B100,2,FALSE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca96293",
   "metadata": {},
   "source": [
    "#### 2.11.2 Figure 2: Aggregated Indicator Scores (Bar Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ab267",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure2_sheet_name='Figure2_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure2_index='=EWU_Dashboard!B6' #selected weighting method\n",
    "figure2_df=pd.DataFrame(columns=act_names)\n",
    "\n",
    "for a,act in enumerate(act_names):\n",
    "    figure2_df.loc[figure2_index,act]=\"=HLOOKUP(A2,INDIRECT(\"+excel_cols[a+1]+\"3\"+\"&\\\"!B1:\"\\\n",
    "                                        +excel_cols[len(Weighting.columns)]+str(len(act_names)+1)+\"\\\"),\"+\\\n",
    "                                        \"VLOOKUP(\"+excel_cols[a+1]+\"1,dict!A2:B100,2,FALSE),FALSE)\"\n",
    "    figure2_df.loc['sheet_name',act]=\"=\\\"W_Ind_\\\"&\"+excel_cols[a+1]+\"4&\\\"_\\\"&EWU_Dashboard!B5\"\n",
    "    figure2_df.loc['db_short',act]=\"=VLOOKUP(EWU_Dashboard!B4,dict!A2:B100,2,FALSE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc523980",
   "metadata": {},
   "source": [
    "#### 2.11.3 Figure 3: Contribution Analysis - Pathways (Bar Chart - Stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20316805",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3_sheet_name='Figure3_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c105b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3_df=pd.DataFrame(columns=LCIA_method_names)\n",
    "fig3_sheet_name=\"=\\\"CA_Pathways_\\\"&B2&\\\"_\\\"&EWU_Dashboard!B5\" #cell B1\n",
    "fig3_db_short=\"=VLOOKUP(EWU_Dashboard!B4,dict!A2:B100,2,FALSE)\" # cell B2\n",
    "\n",
    "for a,act in enumerate(act_names):\n",
    "    for i,IC in enumerate(LCIA_method_names):\n",
    "        figure3_df.loc[act,IC]=\"=INDIRECT(B1&\\\"!\"+excel_cols[i+1]+str(a+2)+\"\\\")\"#+\"*INDIRECT(B3&\\\"!C\"+str(a+2)+\"\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb45391",
   "metadata": {},
   "source": [
    "#### 2.11.4 Figure 4: Contribution Analysis - Processes (Bar Chart - Stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure4_sheet_name='Figure4_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure4_df=pd.DataFrame(columns=LCIA_method_names)\n",
    "fig4_sheet_name=\"=\\\"CA_acts_\\\"&B2&\\\"_\\\"&EWU_Dashboard!B5\" #cell B1\n",
    "fig4_db_short=\"=VLOOKUP(EWU_Dashboard!B4,dict!A2:B100,2,FALSE)\" # cell B2\n",
    "\n",
    "for a,act in enumerate(CA_acts_df.index):\n",
    "    for i,IC in enumerate(LCIA_method_names):\n",
    "        figure4_df.loc[act,IC]=\"=INDIRECT(B1&\\\"!\"+excel_cols[i+1]+str(a+2)+\"\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e3ce64",
   "metadata": {},
   "source": [
    "#### 2.11.5 Figure 5: Scenario Analysis - Foreground System (Bar Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65cf844",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure5_sheet_name='Figure5_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_weightingsets=len(Weighting.columns)\n",
    "n_acts=len(act_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure5_index='=EWU_Dashboard!B3' #selected treatment path / system\n",
    "figure5_df=pd.DataFrame(columns=scenarios)\n",
    "\n",
    "for s,scenario in enumerate(scenarios):\n",
    "    for a,act in enumerate(act_names):\n",
    "        figure5_df.loc[act,scenario]=\"=IF(EWU_Dashboard!B3=A\"+str(a+2)+\",HLOOKUP(EWU_Dashboard!B6,INDIRECT(\"+excel_cols[s+1]\\\n",
    "                                                +str(len(act_names)+2)+\"&\\\"!A1:\"\\\n",
    "                                                +excel_cols[n_weightingsets]+str(n_acts+1)\\\n",
    "                                                +\"\\\"),VLOOKUP(EWU_Dashboard!B3,dict!A2:B100,2,FALSE),FALSE),0)\"\n",
    "    figure5_df.loc['sheet_name',scenario]=\"=\\\"W_Ind_\\\"&\"+excel_cols[s+1]+str(len(act_names)+3)+\"&\\\"_\\\"&\\\"\"+scenario+\"\\\"\"\n",
    "    figure5_df.loc['db_short',scenario]=\"=VLOOKUP(EWU_Dashboard!B4,dict!A2:B100,2,FALSE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7ae5f",
   "metadata": {},
   "source": [
    "#### 2.11.6 Figure 6: Scenario Analysis - Background System (Bar Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure6_sheet_name='Figure6_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure6_index='=EWU_Dashboard!B3' #selected treatment path / system\n",
    "figure6_df=pd.DataFrame(columns=db_names)\n",
    "\n",
    "for d,db in enumerate(db_names):\n",
    "    for a,act in enumerate(act_names):\n",
    "        figure6_df.loc[act,db]=\"=IF(EWU_Dashboard!B3=A\"+str(a+2)+\",HLOOKUP(\"+excel_cols[d+1]+str(len(act_names)+3)+\",INDIRECT(\"+excel_cols[d+1]\\\n",
    "                                            +str(len(act_names)+4)+\"&\\\"!A1:\"\\\n",
    "                                            +excel_cols[n_weightingsets]+str(n_acts+1)\\\n",
    "                                            +\"\\\"),VLOOKUP(EWU_Dashboard!B3,dict!A1:B100,2,FALSE),FALSE),0)\"\n",
    "    figure6_df.loc['scenario',db]=\"=EWU_Dashboard!B5\"\n",
    "    figure6_df.loc['weighting_method',db]=\"=EWU_Dashboard!B6\"\n",
    "    figure6_df.loc['sheet_name',db]=\"=\\\"W_Ind_\\\"&\"+excel_cols[d+1]+\"1&\\\"_\\\"&\"+excel_cols[d+1]+str(len(act_names)+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f74c93",
   "metadata": {},
   "source": [
    "#### 2.11.7 Figure 7: EWU - Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure7_sheet_name='Figure7_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f8e108c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_weightingsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c,col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(figure7_df\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a,act \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(act_names):\n\u001b[0;32m      6\u001b[0m         figure7_df\u001b[38;5;241m.\u001b[39mloc[act,col]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=HLOOKUP(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mexcel_cols[c\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(act_names)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,INDIRECT(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mexcel_cols[c\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\\\n\u001b[0;32m      7\u001b[0m                                             \u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(act_names)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m!A1:\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m----> 8\u001b[0m                                             \u001b[38;5;241m+\u001b[39mexcel_cols[\u001b[43mn_weightingsets\u001b[49m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(n_acts\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\\\n\u001b[0;32m      9\u001b[0m                                             \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m),\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(a\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,FALSE)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m     figure7_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdb_short\u001b[39m\u001b[38;5;124m'\u001b[39m,col]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=VLOOKUP(EWU_Dashboard!B4,dict!A2:B100,2,FALSE)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m     figure7_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscenario\u001b[39m\u001b[38;5;124m'\u001b[39m,col]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=EWU_Dashboard!B5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_weightingsets' is not defined"
     ]
    }
   ],
   "source": [
    "figure7_df=pd.DataFrame(columns=['Treatment', 'Utilization', 'Material'])\n",
    "col_shorts=['Treatm', 'Util', 'Mat']\n",
    "\n",
    "for c,col in enumerate(figure7_df.columns):\n",
    "    for a,act in enumerate(act_names):\n",
    "        figure7_df.loc[act,col]=\"=HLOOKUP(\"+excel_cols[c+1]+str(len(act_names)+4)+\",INDIRECT(\"+excel_cols[c+1]\\\n",
    "                                            +str(len(act_names)+5)+\"&\\\"!A1:\"\\\n",
    "                                            +excel_cols[n_weightingsets]+str(n_acts+1)\\\n",
    "                                            +\"\\\"),\"+str(a+2)+\",FALSE)\"\n",
    "    figure7_df.loc['db_short',col]=\"=VLOOKUP(EWU_Dashboard!B4,dict!A2:B100,2,FALSE)\"\n",
    "    figure7_df.loc['scenario',col]=\"=EWU_Dashboard!B5\"\n",
    "    figure7_df.loc['weighting_method',col]=\"=EWU_Dashboard!B6\"\n",
    "    figure7_df.loc['sheet_name',col]=\"=\\\"WTUM_\\\"&\"+excel_cols[c+1]+str(len(act_names)+2)+\"&\\\"_\\\"&\"+\\\n",
    "                                        excel_cols[c+1]+str(len(act_names)+3)+\"&\\\"_\"+col_shorts[c]+\"\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842ee1d0",
   "metadata": {},
   "source": [
    "## 3. Export to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630eabe2",
   "metadata": {},
   "source": [
    "### 3.1 Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0eb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "EWU_dashboard='EWU_Dashboard.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa974438",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(EWU_dashboard, engine='xlsxwriter')\n",
    "workbook = writer.book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_format = workbook.add_format({'num_format': '0.00','text_wrap':False, \n",
    "                                         'font':'Arial', 'font_size':22,'bold':True, \n",
    "                                         'border':0,'border_color':'black'})\n",
    "subtitle_format = workbook.add_format({'num_format': '0.00','text_wrap':False, \n",
    "                                         'font':'Arial', 'font_size':22,'bold':True, \n",
    "                                         'border':0,'border_color':'black'})\n",
    "text_format = workbook.add_format({'num_format': '0%','text_wrap':False, \n",
    "                                         'font':'Arial', 'font_size':18, \n",
    "                                         'border':1,'border_color':'black'})\n",
    "text_format2 = workbook.add_format({'num_format': '0%','text_wrap':False, \n",
    "                                         'font':'Arial', 'font_size':18, \n",
    "                                         'bold': True, 'font_color': 'white',\n",
    "                                         'fg_color':'#595959',\n",
    "                                         'border':1,'border_color':'black'})\n",
    "heading_format = workbook.add_format({'num_format': '0.00','text_wrap':True, \n",
    "                                         'font':'Arial', 'font_size':10,'bold':True, \n",
    "                                         'border':1,'border_color':'black'})\n",
    "percentage_format = workbook.add_format({'num_format': '0%','text_wrap':True, \n",
    "                                         'font':'Arial', 'font_size':10, \n",
    "                                         'border':1,'border_color':'black'})\n",
    "number_format = workbook.add_format({'num_format': '0.00','text_wrap':True, \n",
    "                                         'font':'Arial', 'font_size':10, \n",
    "                                         'border':1,'border_color':'black'})\n",
    "scientific_format = workbook.add_format({'num_format': '0.00E+00','text_wrap':True, \n",
    "                                         'font':'Arial', 'font_size':10, \n",
    "                                         'border':1,'border_color':'black'})\n",
    "background_format = workbook.add_format({'bg_color':'white'})\n",
    "int_format = workbook.add_format({'num_format': '0','text_wrap':True, \n",
    "                                         'font':'Arial', 'font_size':10, \n",
    "                                         'border':1,'border_color':'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9bdc0f",
   "metadata": {},
   "source": [
    "### 3.2 Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_df=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', sheet_name='Format', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86553238",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(color_df)==0:\n",
    "    color_dict={}\n",
    "else:\n",
    "    color_dict=color_df.iloc[:,0].to_dict()\n",
    "    \n",
    "color_keys=[*act_names, *activity_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd740f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_notincl=[]\n",
    "for ck in color_keys:\n",
    "    if ck not in color_dict.keys():\n",
    "        ck_notincl.append(ck)\n",
    "        \n",
    "add_colors=mcp.gen_color(cmap=\"turbo\",n=len(ck_notincl))\n",
    "\n",
    "for c,ck in enumerate(ck_notincl):\n",
    "    color_dict[ck]=add_colors[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8f07f",
   "metadata": {},
   "source": [
    "### 3.3 Create workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dashboard_sheet=workbook.add_worksheet('EWU_Dashboard')\n",
    "\n",
    "figure1_sheet=workbook.add_worksheet(figure1_sheet_name)\n",
    "figure2_sheet=workbook.add_worksheet(figure2_sheet_name)\n",
    "figure3_sheet=workbook.add_worksheet(figure3_sheet_name)\n",
    "figure4_sheet=workbook.add_worksheet(figure4_sheet_name)\n",
    "figure5_sheet=workbook.add_worksheet(figure5_sheet_name)\n",
    "figure6_sheet=workbook.add_worksheet(figure6_sheet_name)\n",
    "figure7_sheet=workbook.add_worksheet(figure7_sheet_name)\n",
    "documentation_sheet=workbook.add_worksheet('Documentation')\n",
    "dict_sheet=workbook.add_worksheet('dict')\n",
    "\n",
    "Indicator_sheets={}\n",
    "for db_s in Indicator_sheet_names.keys():\n",
    "    Indicator_sheets[db_s]=workbook.add_worksheet(Indicator_sheet_names[db_s])\n",
    "    \n",
    "Weighted_Indicator_sheets={}\n",
    "for db_s in Weighted_Indicator_sheet_names.keys():\n",
    "    Weighted_Indicator_sheets[db_s]=workbook.add_worksheet(Weighted_Indicator_sheet_names[db_s])\n",
    "    \n",
    "Weighting_sheet=workbook.add_worksheet(Weighting_sheet_name)\n",
    "\n",
    "LCA_results_sheets={}\n",
    "for db_s in LCA_results_sheet_names.keys():\n",
    "    LCA_results_sheets[db_s]=workbook.add_worksheet(LCA_results_sheet_names[db_s])\n",
    "\n",
    "CA_Pathways_sheets={}\n",
    "for db_s in CA_Pathways_sheet_names.keys():\n",
    "    CA_Pathways_sheets[db_s]=workbook.add_worksheet(CA_Pathways_sheet_names[db_s])\n",
    "\n",
    "CA_acts_sheets={}\n",
    "for db_s in CA_acts_sheet_names.keys():\n",
    "    CA_acts_sheets[db_s]=workbook.add_worksheet(CA_acts_sheet_names[db_s])\n",
    "\n",
    "params_sheet=workbook.add_worksheet(params_sheet_name)\n",
    "\n",
    "Waste_Gen_sheets={}\n",
    "for db_s in Waste_Gen_sheet_names.keys():\n",
    "    Waste_Gen_sheets[db_s]=workbook.add_worksheet(Waste_Gen_sheet_names[db_s])\n",
    "    \n",
    "Waste_Comp_sheets={}\n",
    "for db_s in Waste_Comp_sheet_names.keys():\n",
    "    Waste_Comp_sheets[db_s]=workbook.add_worksheet(Waste_Comp_sheet_names[db_s])\n",
    "    \n",
    "LCI_df_sheets={}\n",
    "for db_s in LCI_df_sheet_names.keys():    \n",
    "    LCI_df_sheets[db_s]=workbook.add_worksheet(LCI_df_sheet_names[db_s])\n",
    "    \n",
    "LCIAmethod_sheet=workbook.add_worksheet(LCIAmethod_sheet_name)\n",
    "\n",
    "OEV_material_sheets={}\n",
    "for db_s in OEV_material_sheet_names.keys():\n",
    "    OEV_material_sheets[db_s]=workbook.add_worksheet(OEV_material_sheet_names[db_s])\n",
    "    \n",
    "OEV_Pathways_sheets={}\n",
    "for db_s in OEV_Pathways_sheet_names.keys():\n",
    "    OEV_Pathways_sheets[db_s]=workbook.add_worksheet(OEV_Pathways_sheet_names[db_s])\n",
    "    \n",
    "supply_chain_sheets={}\n",
    "for db_s in supply_chain_sheet_names.keys():\n",
    "    supply_chain_sheets[db_s]=workbook.add_worksheet(supply_chain_sheet_names[db_s])\n",
    "    \n",
    "TUM_sheets={}\n",
    "for db_s_m in TUM_sheet_names.keys():\n",
    "    TUM_sheets[db_s_m]=workbook.add_worksheet(TUM_sheet_names[db_s_m])\n",
    "    \n",
    "Weighted_TUM_sheets={}\n",
    "for db_s_m in Weighted_TUM_sheet_names.keys():\n",
    "    Weighted_TUM_sheets[db_s_m]=workbook.add_worksheet(Weighted_TUM_sheet_names[db_s_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4d15c",
   "metadata": {},
   "source": [
    "### 3.4 Write data to workbooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1405d",
   "metadata": {},
   "source": [
    "#### 3.4.1 Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f412b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        Indicator_sheet=Indicator_sheets[db+'_'+s]\n",
    "        for c,col in enumerate(Indicator[db+'_'+s].columns):\n",
    "            Indicator_sheet.write(0,c+1,Indicator[db+'_'+s].columns[c],heading_format)\n",
    "            for i,ind in enumerate(Indicator[db+'_'+s].index):\n",
    "                if c==0:\n",
    "                    Indicator_sheet.write(i+1,0,Indicator[db+'_'+s].index[i],heading_format)\n",
    "                Indicator_sheet.write(i+1,c+1,Indicator[db+'_'+s].loc[ind,col],percentage_format)\n",
    "        Indicator_sheet.set_tab_color('green')\n",
    "        Indicator_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b2e94",
   "metadata": {},
   "source": [
    "#### 3.4.2 Weighted Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Indicator\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        Weighted_Indicator_sheet=Weighted_Indicator_sheets[db+'_'+s]\n",
    "        for c,col in enumerate(Weighted_Indicator[db+'_'+s].columns):\n",
    "            Weighted_Indicator_sheet.write(0,c+1,Weighted_Indicator[db+'_'+s].columns[c],heading_format)    \n",
    "            for i,ind in enumerate(Weighted_Indicator[db+'_'+s].index):\n",
    "                if c==0:\n",
    "                    Weighted_Indicator_sheet.write(i+1,0,Weighted_Indicator[db+'_'+s].index[i],heading_format)\n",
    "                Weighted_Indicator_sheet.write(i+1,c+1,Weighted_Indicator[db+'_'+s].loc[ind,col],percentage_format)\n",
    "        Weighted_Indicator_sheet.set_column_pixels(0,c+1, 100)    \n",
    "        Weighted_Indicator_sheet.set_tab_color('green')\n",
    "        Weighted_Indicator_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa4be8",
   "metadata": {},
   "source": [
    "#### 3.4.3 Weighting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "25984b3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Weighting_sheet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Weighting\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c,col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Weighting\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mWeighting_sheet\u001b[49m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m0\u001b[39m,c\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,Weighting\u001b[38;5;241m.\u001b[39mcolumns[c],heading_format)    \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Weighting\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Weighting_sheet' is not defined"
     ]
    }
   ],
   "source": [
    "# Weighting\n",
    "for c,col in enumerate(Weighting.columns):\n",
    "    Weighting_sheet.write(0,c+1,Weighting.columns[c],heading_format)    \n",
    "    for i,ind in enumerate(Weighting.index):\n",
    "        if c==0:\n",
    "            Weighting_sheet.write(i+1,0,Weighting.index[i],heading_format)\n",
    "        Weighting_sheet.write(i+1,c+1,Weighting.loc[ind,col],percentage_format)\n",
    "Weighting_sheet.set_column_pixels(0,len(Weighting.columns)+1, 100)   \n",
    "Weighting_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e25b61",
   "metadata": {},
   "source": [
    "#### 3.4.4 LCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535daf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCA Results\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        LCA_results_sheet=LCA_results_sheets[db+'_'+s]\n",
    "        for c,col in enumerate(LCA_results[db+'_'+s].columns):\n",
    "            if c>0:\n",
    "                LCA_results_sheet.write(0,c,LCA_results[db+'_'+s].columns[c],heading_format)\n",
    "                for i,ind in enumerate(LCA_results[db+'_'+s].index):\n",
    "                    if c==1:\n",
    "                        LCA_results_sheet.write(i+1,0,LCA_results[db+'_'+s].loc[ind,'Pathway'],heading_format)\n",
    "                    LCA_results_sheet.write(i+1,c,LCA_results[db+'_'+s].loc[ind,col],scientific_format)\n",
    "        LCA_results_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9b6b4",
   "metadata": {},
   "source": [
    "#### 3.4.5 Contribution Analysis - Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA_Pathways\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        CA_Pathways_sheet=CA_Pathways_sheets[db+'_'+s]\n",
    "        for c,col in enumerate(CA_Pathways[db+'_'+s].columns):\n",
    "            CA_Pathways_sheet.write(0,c+1,CA_Pathways[db+'_'+s].columns[c],heading_format)\n",
    "            for i,ind in enumerate(CA_Pathways[db+'_'+s].index):\n",
    "                if c==0:\n",
    "                    CA_Pathways_sheet.write(i+1,0,CA_Pathways[db+'_'+s].index[i],heading_format)\n",
    "                CA_Pathways_sheet.write(i+1,c+1,CA_Pathways[db+'_'+s].loc[ind,col],scientific_format)\n",
    "        CA_Pathways_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b245959",
   "metadata": {},
   "source": [
    "#### 3.4.6 Contribution Analysis - Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA_acts\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        CA_acts_sheet=CA_acts_sheets[db+'_'+s]\n",
    "        for c,col in enumerate(CA_acts[db+'_'+s].columns):\n",
    "            CA_acts_sheet.write(0,c+1,CA_acts[db+'_'+s].columns[c],heading_format)\n",
    "            for i,ind in enumerate(CA_acts[db+'_'+s].index):\n",
    "                if c==0:\n",
    "                    CA_acts_sheet.write(i+1,0,CA_acts[db+'_'+s].index[i],heading_format)\n",
    "                CA_acts_sheet.write(i+1,c+1,CA_acts[db+'_'+s].loc[ind,col],scientific_format)\n",
    "        CA_acts_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511bae9",
   "metadata": {},
   "source": [
    "#### 3.4.7 Supply Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supply_chain\n",
    "for s in scenarios:\n",
    "    for actname in act_names:\n",
    "        supply_chain_sheet=supply_chain_sheets[s+'_'+actname]\n",
    "        for c,col in enumerate(supply_chain[s+'_'+actname].columns):\n",
    "            supply_chain_sheet.write(0,c+1,supply_chain[s+'_'+actname].columns[c],heading_format)\n",
    "            for i,ind in enumerate(supply_chain[s+'_'+actname].index):\n",
    "                if c==0:\n",
    "                    supply_chain_sheet.write(i+1,0,supply_chain[s+'_'+actname].index[i],heading_format)\n",
    "                supply_chain_sheet.write(i+1,c+1,supply_chain[s+'_'+actname].loc[ind,col],scientific_format)\n",
    "        supply_chain_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a2518",
   "metadata": {},
   "source": [
    "#### 3.4.8 EWU-Components: Treatment - Utilization - Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2f8e51ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TUM_sheets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m scenarios:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m TUM_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTreatm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUtil\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMat\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 5\u001b[0m         TUM_sheet\u001b[38;5;241m=\u001b[39m\u001b[43mTUM_sheets\u001b[49m[db\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mTUM_type]\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c,col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(TUM[db\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mTUM_type]\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m      7\u001b[0m             TUM_sheet\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m0\u001b[39m,c\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,TUM[db\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mTUM_type]\u001b[38;5;241m.\u001b[39mcolumns[c],heading_format)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TUM_sheets' is not defined"
     ]
    }
   ],
   "source": [
    "# TUM\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        for TUM_type in ['Treatm', 'Util', 'Mat']:\n",
    "            TUM_sheet=TUM_sheets[db+'_'+s+'_'+TUM_type]\n",
    "            for c,col in enumerate(TUM[db+'_'+s+'_'+TUM_type].columns):\n",
    "                TUM_sheet.write(0,c+1,TUM[db+'_'+s+'_'+TUM_type].columns[c],heading_format)\n",
    "                for i,ind in enumerate(TUM[db+'_'+s+'_'+TUM_type].index):\n",
    "                    if c==0:\n",
    "                        TUM_sheet.write(i+1,0,TUM[db+'_'+s+'_'+TUM_type].index[i],heading_format)\n",
    "                    TUM_sheet.write(i+1,c+1,TUM[db+'_'+s+'_'+TUM_type].loc[ind,col],scientific_format)\n",
    "                    TUM_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd3bfd",
   "metadata": {},
   "source": [
    "#### 3.4.9 Weighted EWU-Components: Treatment - Utilization - Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUM\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        for TUM_type in ['Treatm', 'Util', 'Mat']:\n",
    "            Weighted_TUM_sheet=Weighted_TUM_sheets[db+'_'+s+'_'+TUM_type]\n",
    "            for c,col in enumerate(Weighted_TUM[db+'_'+s+'_'+TUM_type].columns):\n",
    "                Weighted_TUM_sheet.write(0,c+1,Weighted_TUM[db+'_'+s+'_'+TUM_type].columns[c],heading_format)\n",
    "                for i,ind in enumerate(Weighted_TUM[db+'_'+s+'_'+TUM_type].index):\n",
    "                    if c==0:\n",
    "                        Weighted_TUM_sheet.write(i+1,0,Weighted_TUM[db+'_'+s+'_'+TUM_type].index[i],heading_format)\n",
    "                    Weighted_TUM_sheet.write(i+1,c+1,Weighted_TUM[db+'_'+s+'_'+TUM_type].loc[ind,col],scientific_format)\n",
    "                    Weighted_TUM_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270c149",
   "metadata": {},
   "source": [
    "#### 3.4.10 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67221d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "for c,col in enumerate(parameter_df.columns):\n",
    "    if c>0:\n",
    "        params_sheet.write(0,c,parameter_df.columns[c],heading_format)\n",
    "        for i,ind in enumerate(parameter_df.index):\n",
    "            if c==1:\n",
    "                params_sheet.write(i+1,0,str(parameter_df.loc[ind,'Parameter-ID']),heading_format)\n",
    "            if col == 'Group':\n",
    "                if pd.isnull(parameter_df.loc[ind,col])==False:\n",
    "                    params_sheet.write(i+1,c,parameter_df.loc[ind,col],int_format)\n",
    "                else:\n",
    "                    params_sheet.write(i+1,c,'None',int_format)\n",
    "            else:\n",
    "                try:\n",
    "                    params_sheet.write(i+1,c,parameter_df.loc[ind,col],scientific_format)\n",
    "                except:\n",
    "                    pass\n",
    "params_sheet.set_column_pixels(1,len(parameter_df.columns)+1, 100)  \n",
    "\n",
    "sc_format = workbook.add_format({'bold': 1, 'bg_color': 'yellow'})\n",
    "col_default = excel_cols[parameter_df.columns.get_loc(\"Parameter Value - \"+scenarios[0])]\n",
    "scenario_cols=[col for col in parameter_df.columns if ('Parameter Value' in col) and ('Parameter Value - default' not in col)]\n",
    "for i in parameter_df.index:\n",
    "    for col in scenario_cols:\n",
    "        col_name = excel_cols[parameter_df.columns.get_loc(col)]\n",
    "        cell=col_name+str(i+2)\n",
    "        params_sheet.conditional_format(cell, \n",
    "                                        {'type': 'cell',\n",
    "                                                 'criteria': \"not equal to\",\n",
    "                                                 'value': col_default+str(i+2),\n",
    "                                                 'format': sc_format})\n",
    "    \n",
    "if general_info['Conduct perturbation analysis'] == 'yes':\n",
    "    col_x = parameter_df.columns.get_loc(LCIA_method_names[0])\n",
    "    #col_y = parameter_df.columns.get_loc(LCIA_method_names[-1]) + 1\n",
    "    for i,IC in enumerate(LCIA_method_names):\n",
    "        min_val=parameter_df[IC].min()\n",
    "        max_val=parameter_df[IC].max()\n",
    "        cells=excel_cols[col_x+i]+str(2)+':'+excel_cols[col_x+i]+str(len(parameter_df)+2)\n",
    "        params_sheet.conditional_format(cells, {'type': '3_color_scale',\n",
    "                                             'min_color': \"#C00000\",\n",
    "                                             'mid_color': \"#FFFFFF\",\n",
    "                                             'max_color': \"#9BBB59\",\n",
    "                                             'min_value':min_val,\n",
    "                                             'mid_value':0,\n",
    "                                             'max_value':max_val})\n",
    "\n",
    "#params_sheet.set_tab_color('yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ef602",
   "metadata": {},
   "source": [
    "#### 3.4.11 Waste Quantitities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waste Generation\n",
    "for s in scenarios:\n",
    "    Waste_Gen_sheet=Waste_Gen_sheets[s]\n",
    "    for c,col in enumerate(Waste_Gen[s].columns):\n",
    "        Waste_Gen_sheet.write(0,c+1,Waste_Gen[s].columns[c],heading_format)    \n",
    "        for i,ind in enumerate(Waste_Gen[s].index):\n",
    "            if c==0:\n",
    "                Waste_Gen_sheet.write(i+1,0,Waste_Gen[s].index[i],heading_format)\n",
    "                Waste_Gen_sheet.write(i+1,c+1,Waste_Gen[s].loc[ind,col],percentage_format)\n",
    "            if c==1:\n",
    "                Waste_Gen_sheet.write(i+1,c+1,Waste_Gen[s].loc[ind,col],number_format)\n",
    "    Waste_Gen_sheet.set_column_pixels(0,len(Waste_Gen[s].columns)+1, 100)  \n",
    "    Waste_Gen_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d261ead",
   "metadata": {},
   "source": [
    "#### 3.4.12 Waste Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf6512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waste Composition\n",
    "for s in scenarios:\n",
    "    Waste_Comp_sheet=Waste_Comp_sheets[s]\n",
    "    for c,col in enumerate(Waste_Comp[s].columns):\n",
    "        Waste_Comp_sheet.write(0,c+1,Waste_Comp[s].columns[c],heading_format)    \n",
    "        for i,ind in enumerate(Waste_Comp[s].index):\n",
    "            if c==0:\n",
    "                Waste_Comp_sheet.write(i+1,0,Waste_Comp[s].index[i],heading_format)\n",
    "            try:\n",
    "                Waste_Comp_sheet.write(i+1,c+1,Waste_Comp[s].loc[ind,col],percentage_format)\n",
    "            except:\n",
    "                pass\n",
    "    Waste_Comp_sheet.set_column_pixels(0,len(Waste_Comp[s].columns)+1, 100)\n",
    "    Waste_Comp_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390894c5",
   "metadata": {},
   "source": [
    "#### 3.4.13 LCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCI\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        LCI_df_sheet=LCI_df_sheets[db+'_'+s]\n",
    "        for c,col in enumerate(LCI_dbs[db+'_'+s].columns):\n",
    "            LCI_df_sheet.write(0,c,LCI_dbs[db+'_'+s].columns[c],heading_format)\n",
    "            for i,ind in enumerate(LCI_dbs[db+'_'+s].index):\n",
    "                try:\n",
    "                    LCI_df_sheet.write(i+1,c,LCI_dbs[db+'_'+s].loc[ind,col],number_format)\n",
    "                except:\n",
    "                    pass\n",
    "        LCI_df_sheet.set_column_pixels(1,len(LCI_dbs[db+'_'+s].columns)+1, 100)\n",
    "        LCI_df_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd97a3",
   "metadata": {},
   "source": [
    "#### 3.4.14 Original Environmental Value (Material Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Environmental Value - materials\n",
    "for db in db_names:\n",
    "    OEV_material_sheet=OEV_material_sheets[db]\n",
    "    for c,col in enumerate(OEV_materials[db].columns):\n",
    "        OEV_material_sheet.write(0,c+1,OEV_materials[db].columns[c],heading_format)    \n",
    "        for i,ind in enumerate(OEV_materials[db].index):\n",
    "            if c==0:\n",
    "                OEV_material_sheet.write(i+1,0,OEV_materials[db].index[i],heading_format)\n",
    "            try:\n",
    "                OEV_material_sheet.write(i+1,c+1,OEV_materials[db].loc[ind,col],scientific_format)\n",
    "            except:\n",
    "                pass\n",
    "    OEV_material_sheet.set_column_pixels(0,len(OEV_materials[db].columns)+1, 100)\n",
    "    OEV_material_sheet.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a3e7f4a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OEV_Pathways_sheets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m db \u001b[38;5;129;01min\u001b[39;00m db_names:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m scenarios:\n\u001b[1;32m----> 4\u001b[0m         OEV_Pathways_sheet\u001b[38;5;241m=\u001b[39m\u001b[43mOEV_Pathways_sheets\u001b[49m[db\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms]\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c,col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(OEV_Pathways[db\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms]\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m      6\u001b[0m             OEV_Pathways_sheet\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m0\u001b[39m,c\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,OEV_Pathways[db\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms]\u001b[38;5;241m.\u001b[39mcolumns[c],heading_format)    \n",
      "\u001b[1;31mNameError\u001b[0m: name 'OEV_Pathways_sheets' is not defined"
     ]
    }
   ],
   "source": [
    "# Original Environmental Value - Treatment Paths\n",
    "for db in db_names:\n",
    "    for s in scenarios:\n",
    "        OEV_Pathways_sheet=OEV_Pathways_sheets[db+'_'+s]\n",
    "        for c,col in enumerate(OEV_Pathways[db+'_'+s].columns):\n",
    "            OEV_Pathways_sheet.write(0,c+1,OEV_Pathways[db+'_'+s].columns[c],heading_format)    \n",
    "            for i,ind in enumerate(OEV_Pathways[db+'_'+s].index):\n",
    "                if c==0:\n",
    "                    OEV_Pathways_sheet.write(i+1,0,OEV_Pathways[db+'_'+s].index[i],heading_format)\n",
    "                try:\n",
    "                    OEV_Pathways_sheet.write(i+1,c+1,OEV_Pathways[db+'_'+s].loc[ind,col],scientific_format)\n",
    "                except:\n",
    "                    pass\n",
    "        OEV_Pathways_sheet.set_column_pixels(0,len(OEV_Pathways[db+'_'+s].columns)+1, 100)  \n",
    "        OEV_Pathways_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33dcff3",
   "metadata": {},
   "source": [
    "#### 3.4.15 Normalization Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NormalizationFactor\n",
    "for c,col in enumerate(LCIAmethod_df.columns):\n",
    "    LCIAmethod_sheet.write(0,c+1,LCIAmethod_df.columns[c],heading_format)\n",
    "    for i,ind in enumerate(LCIAmethod_df.index):\n",
    "        if c==0:\n",
    "            LCIAmethod_sheet.write(i+1,0,LCIAmethod_df.index[i],heading_format)\n",
    "        LCIAmethod_sheet.write(i+1,c+1,LCIAmethod_df.loc[ind,col],scientific_format)\n",
    "        \n",
    "LCIAmethod_sheet.set_column_pixels(1,1, 300)\n",
    "LCIAmethod_sheet.set_column_pixels(3,3, 100)\n",
    "LCIAmethod_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416176e0",
   "metadata": {},
   "source": [
    "#### 3.4.16 Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df=pd.DataFrame(columns=['long','short'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b590f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for a,act in enumerate(Indicator_db.index):\n",
    "    dict_df.loc[i,'long']=act\n",
    "    dict_df.loc[i,'short']=i+2\n",
    "    i=i+1\n",
    "    \n",
    "for d,db in enumerate(db_names):\n",
    "    dict_df.loc[i,'long']=dbs[d].name\n",
    "    dict_df.loc[i,'short']=db\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "for c,col in enumerate(dict_df.columns):\n",
    "    dict_sheet.write(0,c,dict_df.columns[c],heading_format)\n",
    "    for i,ind in enumerate(dict_df.index):\n",
    "        dict_sheet.write(i+1,c,dict_df.loc[ind,col])\n",
    "        \n",
    "dict_sheet.set_column_pixels(1,1, 300)\n",
    "dict_sheet.set_column_pixels(3,3, 100)\n",
    "dict_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85154ac2",
   "metadata": {},
   "source": [
    "#### 3.4.17 Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get locally imported modules from current notebook\n",
    "#htPathways://stackoverflow.com/questions/40428931/package-for-listing-version-of-packages-used-in-a-jupyter-notebook\n",
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0b62c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_references=pd.read_excel('ExcelTool_GeneratorInput_Template.xlsx', \n",
    "                                   sheet_name='Activities')[['Activity code', \n",
    "                                                            'Activity name',\n",
    "                                                           'Unit',\n",
    "                                                           'Location','Reference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b3dfd6f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requirements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m package_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p,package \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mrequirements\u001b[49m):\n\u001b[0;32m      3\u001b[0m     package_df\u001b[38;5;241m.\u001b[39mloc[p,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpackage[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m     package_df\u001b[38;5;241m.\u001b[39mloc[p,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpackage[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requirements' is not defined"
     ]
    }
   ],
   "source": [
    "package_df=pd.DataFrame()\n",
    "for p,package in enumerate(requirements):\n",
    "    package_df.loc[p,'package']=package[0]\n",
    "    package_df.loc[p,'version']=package[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8567be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_references=activity_references.replace(np.nan, 'Assumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f54dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_doc=premise_scenarios.dropna(axis=1,how='all').dropna()\n",
    "premise_doc=premise_doc.reset_index(drop=True)\n",
    "premise_doc['Update']=[str([i for i in premise_update.index]) for i in range(len(premise_doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43687cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,col in enumerate(activity_references.columns):\n",
    "    documentation_sheet.write(0,c,activity_references.columns[c],heading_format)\n",
    "    for i,ind in enumerate(activity_references.index):\n",
    "        documentation_sheet.write(i+1,c,activity_references.loc[ind,col],percentage_format)\n",
    "        \n",
    "first_row=len(activity_references)+5\n",
    "\n",
    "for c,col in enumerate(package_df.columns):\n",
    "    documentation_sheet.write(first_row,c,package_df.columns[c],heading_format)\n",
    "    for i,ind in enumerate(package_df.index):\n",
    "        documentation_sheet.write(i+1+first_row,c,package_df.loc[ind,col],percentage_format)\n",
    "        \n",
    "documentation_sheet.write(first_row+len(package_df)+2,0,'Database',percentage_format)\n",
    "documentation_sheet.write(first_row+len(package_df)+2,1,general_info['Database name'],percentage_format)\n",
    "\n",
    "documentation_sheet.write(first_row+len(package_df)+4,0,'Background system scenarios',heading_format)\n",
    "for c,col in enumerate(premise_doc.columns):\n",
    "    documentation_sheet.write(first_row+len(package_df)+5,c,str(premise_doc.columns[c]),heading_format)\n",
    "    for i,ind in enumerate(premise_doc.index):\n",
    "        documentation_sheet.write(i+1+first_row+len(package_df)+5,c,premise_doc.loc[ind,col],percentage_format)\n",
    "\n",
    "documentation_sheet.set_column_pixels(0,4, 300)\n",
    "documentation_sheet.set_column_pixels(2,3, 100)\n",
    "\n",
    "documentation_sheet.hide_gridlines(option=2)\n",
    "documentation_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4359d2fa",
   "metadata": {},
   "source": [
    "#### 3.4.18 Figure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure1\n",
    "for c,col in enumerate(figure1_df.columns):\n",
    "    figure1_sheet.write(0,c+1,col,heading_format)\n",
    "    for i,ind in enumerate(figure1_df.index):\n",
    "        if c==0:\n",
    "            figure1_sheet.write(i+1,0,figure1_df.index[i],heading_format)\n",
    "        cell=excel_cols[c+1]+str(i+2)\n",
    "        figure1_sheet.write_dynamic_array_formula(cell,formula=figure1_df.loc[ind,col], cell_format=percentage_format)\n",
    "figure1_sheet.set_tab_color('orange')\n",
    "figure1_sheet.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure2\n",
    "for c,col in enumerate(figure2_df.columns):\n",
    "    figure2_sheet.write(0,c+1,col,heading_format)\n",
    "    for i,ind in enumerate(figure2_df.index):\n",
    "        if c==0:\n",
    "            figure2_sheet.write(i+1,0,figure2_df.index[i],heading_format)\n",
    "        cell=excel_cols[c+1]+str(i+2)\n",
    "        figure2_sheet.write_dynamic_array_formula(cell,formula=figure2_df.loc[ind,col], cell_format=percentage_format)\n",
    "figure2_sheet.set_tab_color('orange')\n",
    "figure2_sheet.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3be1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure3\n",
    "figure3_sheet.write('A1','sheet_name',heading_format)\n",
    "figure3_sheet.write('A2','db_short',heading_format)\n",
    "#figure3_sheet.write('A3','wg_sheet_name',heading_format)\n",
    "figure3_sheet.write('B1',fig3_sheet_name,heading_format)\n",
    "figure3_sheet.write('B2',fig3_db_short,heading_format)\n",
    "#figure3_sheet.write('B3',fig3_wg_sheet_name,heading_format)\n",
    "\n",
    "for c,col in enumerate(figure3_df.columns):\n",
    "    figure3_sheet.write(4,c+1,col,heading_format)\n",
    "    for i,ind in enumerate(figure3_df.index):\n",
    "        if c==0:\n",
    "            figure3_sheet.write(i+5,0,figure3_df.index[i],heading_format)\n",
    "        cell=excel_cols[c+1]+str(i+6)\n",
    "        figure3_sheet.write_dynamic_array_formula(cell,formula=figure3_df.loc[ind,col], cell_format=scientific_format)\n",
    "figure3_sheet.set_tab_color('orange')\n",
    "figure3_sheet.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure4\n",
    "figure4_sheet.write('A1','sheet_name',heading_format)\n",
    "figure4_sheet.write('A2','db_short',heading_format)\n",
    "figure4_sheet.write('B1',fig4_sheet_name,heading_format)\n",
    "figure4_sheet.write('B2',fig4_db_short,heading_format)\n",
    "\n",
    "for c,col in enumerate(figure4_df.columns):\n",
    "    figure4_sheet.write(4,c+1,col,heading_format)\n",
    "    for i,ind in enumerate(figure4_df.index):\n",
    "        if c==0:\n",
    "            figure4_sheet.write(i+5,0,figure4_df.index[i],heading_format)\n",
    "        cell=excel_cols[c+1]+str(i+6)\n",
    "        figure4_sheet.write_dynamic_array_formula(cell,formula=figure4_df.loc[ind,col], cell_format=scientific_format)\n",
    "figure4_sheet.set_tab_color('orange')\n",
    "figure4_sheet.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure5\n",
    "for c,col in enumerate(figure5_df.columns):\n",
    "    figure5_sheet.write(0,c+1,col,heading_format)\n",
    "    for i,ind in enumerate(figure5_df.index):\n",
    "        if c==0:\n",
    "            figure5_sheet.write(i+1,0,figure5_df.index[i],heading_format)\n",
    "        cell=excel_cols[c+1]+str(i+2)\n",
    "        figure5_sheet.write_dynamic_array_formula(cell,formula=figure5_df.loc[ind,col], cell_format=percentage_format)\n",
    "figure5_sheet.set_tab_color('orange')\n",
    "figure5_sheet.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure6\n",
    "for c,col in enumerate(figure6_df.columns):\n",
    "    figure6_sheet.write(0,c+1,col,heading_format)\n",
    "    for i,ind in enumerate(figure6_df.index):\n",
    "        if c==0:\n",
    "            figure6_sheet.write(i+1,0,figure6_df.index[i],heading_format)\n",
    "        cell=excel_cols[c+1]+str(i+2)\n",
    "        figure6_sheet.write_dynamic_array_formula(cell,formula=figure6_df.loc[ind,col], cell_format=percentage_format)\n",
    "figure6_sheet.set_tab_color('orange')\n",
    "figure6_sheet.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64016f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure7\n",
    "for c,col in enumerate(figure7_df.columns):\n",
    "    figure7_sheet.write(0,c+1,col,heading_format)\n",
    "    for i,ind in enumerate(figure7_df.index):\n",
    "        if c==0:\n",
    "            figure7_sheet.write(i+1,0,figure7_df.index[i],heading_format)\n",
    "        cell=excel_cols[c+1]+str(i+2)\n",
    "        figure7_sheet.write_dynamic_array_formula(cell,formula=figure7_df.loc[ind,col], cell_format=scientific_format)\n",
    "figure7_sheet.set_tab_color('orange')\n",
    "figure7_sheet.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c74349",
   "metadata": {},
   "source": [
    "#### 3.4.19 Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "waste=general_info['Type of waste']\n",
    "geo=general_info['Geographical scope']\n",
    "time=general_info['Temporal scope']\n",
    "title=f'Treatment of {waste}, {geo}, {time}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c78d2",
   "metadata": {},
   "source": [
    "**Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dashboard_sheet.set_column(0, 200, 100, background_format)\n",
    "Dashboard_sheet.set_column(0, 0, 50, background_format)\n",
    "Dashboard_sheet.set_column(1, 1, 60, background_format)\n",
    "\n",
    "\n",
    "Dashboard_sheet.write('A1',title,title_format)\n",
    "Dashboard_sheet.write('A9','Environmental Waste Utilization', title_format)\n",
    "Dashboard_sheet.write('C9','Contribution Analysis', title_format)\n",
    "Dashboard_sheet.write('P9','Scenario Analysis', title_format)\n",
    "\n",
    "Dashboard_sheet.write('A3','Pathway/WMS',text_format2)\n",
    "Dashboard_sheet.write('B3',act_names[0],text_format)\n",
    "Dashboard_sheet.data_validation('B3', {'validate': 'list',\n",
    "                                 'source': act_names})\n",
    "\n",
    "Dashboard_sheet.write('A4','Database',text_format2)\n",
    "Dashboard_sheet.write('B4',[db.name for db in dbs][0],text_format)\n",
    "Dashboard_sheet.data_validation('B4', {'validate': 'list',\n",
    "                                 'source': [db.name for db in dbs]})\n",
    "\n",
    "Dashboard_sheet.write('A5','Scenario',text_format2)\n",
    "Dashboard_sheet.write('B5',scenarios[0],text_format)\n",
    "Dashboard_sheet.data_validation('B5', {'validate': 'list',\n",
    "                                 'source': scenarios})\n",
    "\n",
    "Dashboard_sheet.write('A6','Weighting Method',text_format2)\n",
    "Dashboard_sheet.write('B6',Weighting.columns[0],text_format)\n",
    "Dashboard_sheet.data_validation('B6', {'validate': 'list',\n",
    "                                 'source': '=Weighting!B1:'+str(excel_cols[len(Weighting.columns)])+'1'})\n",
    "\n",
    "Dashboard_sheet.set_zoom(30)\n",
    "Dashboard_sheet.hide_gridlines(option=2) #hide gridlines on screen and printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bf9b0b",
   "metadata": {},
   "source": [
    "**Figure1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63569e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = workbook.add_chart({'type': 'radar', 'subtype':'filled'})\n",
    "\n",
    "# Get the number of rows and column index\n",
    "max_col = len(LCIA_method_names)\n",
    "col_x = figure1_df.columns.get_loc(LCIA_method_names[0]) + 1\n",
    "col_y = figure1_df.columns.get_loc(LCIA_method_names[-1]) + 1\n",
    "\n",
    "max_row = len(act_names)\n",
    "\n",
    "for i,ind in enumerate(figure5_df.index[:max_row]):\n",
    "    row_x = figure1_df.index.get_loc(ind) + 1\n",
    "    chart.add_series({\n",
    "        'name':       ['EWU_Dashboard', 2, 1, 2, 1],\n",
    "        'categories': [figure1_sheet_name, 0, col_x, 0, max_col], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure1_sheet_name, row_x, col_x, row_x, col_y],\n",
    "        'line':       {'color': color_dict[ind]},\n",
    "        'fill':       {'color': color_dict[ind], 'transparency': 50},\n",
    "        #'marker':     {'type': 'circle', 'size': 4},\n",
    "        #'trendline': {'type': 'linear'},\n",
    "    })\n",
    "    # Set name on axis\n",
    "#     chart.set_x_axis({'name': 'Concentration'})\n",
    "    chart.set_y_axis({'name': 'Measured','major_unit': 1}) #'min': -1, 'max': 2,\n",
    "                      #'major_gridlines': {'visible': False}},\n",
    "    chart.set_size({'width': 700, 'height': 370})\n",
    "    chart.set_legend({'none': True})\n",
    "\n",
    "    Dashboard_sheet.insert_chart('A10', chart)\n",
    "    # Close and save the Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39219a29",
   "metadata": {},
   "source": [
    "**Figure2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165467df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Results - figure2_df Aggregated Scores\n",
    "# Add charts\n",
    "\n",
    "# Create a chart object.\n",
    "act_colors=[color_dict[act] for act in act_names]\n",
    "\n",
    "n=0\n",
    "for i,ind in enumerate(figure2_df.index[:1]):\n",
    "    chart = workbook.add_chart({'type': 'column'})\n",
    "    # Get the number of rows and column index\n",
    "    max_col = len(LCIA_method_names)\n",
    "    col_x = figure2_df.columns.get_loc(act_names[0]) + 1\n",
    "    col_y = figure2_df.columns.get_loc(act_names[-1]) + 1\n",
    "    row_x = figure2_df.index.get_loc(ind) + 1\n",
    "    # Create the bar chart\n",
    "    chart.add_series({\n",
    "        'name':       ['EWU_Dashboard', 5, 1, 5, 1],\n",
    "        'categories': [figure2_sheet_name, 0, col_x, 0, max_col], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure2_sheet_name, row_x, col_x, row_x, col_y],\n",
    "        'points':     [{'fill': {'color': act_color}} for act_color in act_colors],\n",
    "        #'fill':       {'color': act_colors},\n",
    "        #'marker':     {'type': 'circle', 'size': 4},\n",
    "        #'trendline': {'type': 'linear'},\n",
    "    })\n",
    "    # Set name on axis\n",
    "#     chart.set_x_axis({'name': 'Concentration'})\n",
    "    chart.set_y_axis({'name': 'Indicator Score',})#'min': -1, 'max': 2,'major_unit': 1})\n",
    "                      #'major_gridlines': {'visible': False}},\n",
    "    chart.set_size({'width': 700, 'height': 370})\n",
    "    chart.set_legend({'none': True})\n",
    "\n",
    "    Dashboard_sheet.insert_chart('A30', chart)\n",
    "    \n",
    "    # Close and save the Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e53d3b",
   "metadata": {},
   "source": [
    "**Figure3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results - Contribution Analysis (Pathways)\n",
    "# Add charts\n",
    "\n",
    "# Create a chart object.\n",
    "chart = workbook.add_chart({'type': 'column', 'subtype': 'stacked'})\n",
    "max_col = len(LCIA_method_names)\n",
    "col_x = figure3_df.columns.get_loc(LCIA_method_names[0]) + 1\n",
    "col_y = figure3_df.columns.get_loc(LCIA_method_names[-1]) + 1\n",
    "first_row=4\n",
    "max_row = len(figure3_df.index)+4\n",
    "\n",
    "for i,ind in enumerate(figure3_df.index[1:]):\n",
    "    # Get the number of rows and column index\n",
    "\n",
    "    # Create the scatter plot, use a trendline to fit it\n",
    "    chart.add_series({\n",
    "        'name':       ind,\n",
    "        'categories': [figure3_sheet_name, first_row, col_x, first_row, col_y], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure3_sheet_name, i+first_row+2, col_x, i+first_row+2, col_y],\n",
    "        'fill':       {'color': color_dict[ind]},\n",
    "    })\n",
    "    # Set name on axis\n",
    "chart.set_x_axis({'label_position':'low'})\n",
    "chart.set_y_axis({'name': 'Environmental Impact in Person Equivalents'})\n",
    "                  #'major_gridlines': {'visible': False}},\n",
    "chart.set_size({'width': 7500, 'height': 370})\n",
    "#chart.set_legend({'none': True})\n",
    "chart.set_title({'name':'Contribution Analysis - Treatment Paths'})\n",
    "\n",
    "line_chart = workbook.add_chart({'type': 'line'})\n",
    "line_chart.add_series({     \n",
    "        'name':       [figure3_sheet_name, first_row+1, 0],\n",
    "        'categories': [figure3_sheet_name, first_row, col_x, first_row, col_y], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure3_sheet_name, first_row+1, col_x, first_row+1, col_y],\n",
    "        'line':       {'color': 'black','transparency':100},\n",
    "        'marker':     {'border': {'color':'black'}, 'fill': {'color':'black'},'size':5,'type': 'diamond'}\n",
    "        })\n",
    "\n",
    "chart.combine(line_chart)\n",
    "\n",
    "Dashboard_sheet.insert_chart('C10', chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee811a",
   "metadata": {},
   "source": [
    "**Figure4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb88d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results - Contribution Analysis (Pathways)\n",
    "# Add charts\n",
    "\n",
    "# Create a chart object.\n",
    "chart = workbook.add_chart({'type': 'column', 'subtype': 'stacked'})\n",
    "max_col = len(LCIA_method_names)\n",
    "col_x = figure4_df.columns.get_loc(LCIA_method_names[0]) + 1\n",
    "col_y = figure4_df.columns.get_loc(LCIA_method_names[-1]) + 1\n",
    "first_row=4\n",
    "max_row = len(figure4_df.index)+4\n",
    "\n",
    "for i,ind in enumerate(figure4_df.index):\n",
    "    # Get the number of rows and column index\n",
    "\n",
    "    # Create the scatter plot, use a trendline to fit it\n",
    "    chart.add_series({\n",
    "        'name':       ind,\n",
    "        'categories': [figure4_sheet_name, first_row, col_x, first_row, col_y], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure4_sheet_name, i+first_row+1, col_x, i+first_row+1, col_y],\n",
    "        'fill':       {'color': color_dict[ind]},\n",
    "    })\n",
    "    # Set name on axis\n",
    "chart.set_x_axis({'label_position':'low'})\n",
    "chart.set_y_axis({'name': 'Environmental Impact in Person Equivalents'})\n",
    "                  #'major_gridlines': {'visible': False}},\n",
    "chart.set_size({'width': 7500, 'height': 370})\n",
    "#chart.set_legend({'none': True})\n",
    "chart.set_title({'name':'Contribution Analysis - Activities'})\n",
    "\n",
    "line_chart = workbook.add_chart({'type': 'line'})\n",
    "line_chart.add_series({     \n",
    "        'name':       [figure3_sheet_name, first_row+1, 0],\n",
    "        'categories': [figure3_sheet_name, first_row, col_x, first_row, col_y], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure3_sheet_name, first_row+1, col_x, first_row+1, col_y],\n",
    "        'line':       {'color': 'black','transparency':100},\n",
    "        'marker':     {'border': {'color':'black'}, 'fill': {'color':'black'},'size':5,'type': 'diamond'}\n",
    "        })\n",
    "\n",
    "chart.combine(line_chart)\n",
    "\n",
    "Dashboard_sheet.insert_chart('C30', chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae149c7e",
   "metadata": {},
   "source": [
    "**Figure5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: Results - figure5_df Aggregated Scores\n",
    "# Add charts\n",
    "\n",
    "# Create a chart object.\n",
    "act_colors=[color_dict[act] for act in act_names]\n",
    "\n",
    "n=0\n",
    "# Create a chart object.\n",
    "chart = workbook.add_chart({'type': 'column', 'subtype': 'stacked'})\n",
    "col_x = 1\n",
    "col_y = len(figure5_df.columns)\n",
    "first_row=0\n",
    "max_row = len(act_names)\n",
    "\n",
    "for i,ind in enumerate(figure5_df.index[:max_row]):\n",
    "    # Get the number of rows and column index\n",
    "\n",
    "    # Create the scatter plot, use a trendline to fit it\n",
    "    chart.add_series({\n",
    "        'name':       ind,\n",
    "        'categories': [figure5_sheet_name, first_row, col_x, first_row, col_y], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure5_sheet_name, i+first_row+1, col_x, i+first_row+1, col_y],\n",
    "        'fill':       {'color': color_dict[ind]},\n",
    "    })\n",
    "    # Set name on axis\n",
    "#     chart.set_x_axis({'name': 'Concentration'})\n",
    "chart.set_y_axis({'name': 'Indicator Score',})#'min': -1, 'max': 2,'major_unit': 1})\n",
    "                  #'major_gridlines': {'visible': False}},\n",
    "chart.set_size({'width': 7500, 'height': 370})\n",
    "chart.set_legend({'none': True})\n",
    "chart.set_title({'name': 'EWU_Dashboard!B3'})\n",
    "\n",
    "Dashboard_sheet.insert_chart('P10', chart)\n",
    "    \n",
    "    # Close and save the Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf000ca",
   "metadata": {},
   "source": [
    "**Figure6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6: Results - figure6_df Aggregated Scores\n",
    "# Add charts\n",
    "\n",
    "# Create a chart object.\n",
    "act_colors=[color_dict[act] for act in act_names]\n",
    "\n",
    "n=0\n",
    "# Create a chart object.\n",
    "chart = workbook.add_chart({'type': 'column', 'subtype': 'stacked'})\n",
    "col_x = 1\n",
    "col_y = len(figure6_df.columns)\n",
    "first_row=0\n",
    "max_row = len(act_names)\n",
    "\n",
    "for i,ind in enumerate(figure6_df.index[:max_row]):\n",
    "    # Get the number of rows and column index\n",
    "\n",
    "    # Create the scatter plot, use a trendline to fit it\n",
    "    chart.add_series({\n",
    "        'name':       ind,\n",
    "        'categories': [figure6_sheet_name, first_row, col_x, first_row, col_y], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure6_sheet_name, i+first_row+1, col_x, i+first_row+1, col_y],\n",
    "        'fill':       {'color': color_dict[ind]},\n",
    "    })\n",
    "    # Set name on axis\n",
    "#     chart.set_x_axis({'name': 'Concentration'})\n",
    "chart.set_y_axis({'name': 'Indicator Score',})#'min': -1, 'max': 2,'major_unit': 1})\n",
    "                  #'major_gridlines': {'visible': False}},\n",
    "chart.set_size({'width': 7500, 'height': 370})\n",
    "chart.set_legend({'none': True})\n",
    "chart.set_title({'name': 'EWU_Dashboard!B3'})\n",
    "\n",
    "Dashboard_sheet.insert_chart('P30', chart)\n",
    "    \n",
    "    # Close and save the Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4db77f",
   "metadata": {},
   "source": [
    "**Figure7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb26f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7: Results - figure7_df Aggregated Scores\n",
    "# Add charts\n",
    "\n",
    "# Create a chart object.\n",
    "act_colors=[color_dict[act] for act in act_names]\n",
    "\n",
    "n=0\n",
    "# Create a chart object.\n",
    "chart = workbook.add_chart({'type': 'column'})\n",
    "col_x = 1\n",
    "col_y = len(figure7_df.columns)\n",
    "first_row=0\n",
    "max_row = len(act_names)\n",
    "\n",
    "for i,ind in enumerate(figure7_df.index[:max_row]):\n",
    "    # Get the number of rows and column index\n",
    "\n",
    "    # Create the scatter plot, use a trendline to fit it\n",
    "    chart.add_series({\n",
    "        'name':       ind,\n",
    "        'categories': [figure7_sheet_name, first_row, col_x, first_row, col_y], #[sheetname, first_row, first_col, last_row, last_col]\n",
    "        'values':     [figure7_sheet_name, i+first_row+1, col_x, i+first_row+1, col_y],\n",
    "        'fill':       {'color': color_dict[ind]},\n",
    "    })\n",
    "chart.set_x_axis({'label_position':'low'})\n",
    "chart.set_y_axis({'name': 'Environmental Impact in Person Equivalents',})#'min': -1, 'max': 2,'major_unit': 1})\n",
    "                  #'major_gridlines': {'visible': False}},\n",
    "chart.set_size({'width': 700, 'height': 370})\n",
    "chart.set_legend({'none': True})\n",
    "chart.set_title({'name': 'EWU-Components'})\n",
    "\n",
    "Dashboard_sheet.insert_chart('A50', chart)\n",
    "    \n",
    "    # Close and save the Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1a1d4",
   "metadata": {},
   "source": [
    "### 3.5 Save & Close "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9b5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca2198",
   "metadata": {},
   "source": [
    "### 3.6 Insert User Guide and Glossar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff46a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from win32com.client import Dispatch\n",
    "\n",
    "path1 = os.path.abspath('ExcelTool_GeneratorInput_Template.xlsx')\n",
    "path2 = os.path.abspath(EWU_dashboard)\n",
    "\n",
    "xl = Dispatch(\"Excel.Application\")\n",
    "xl.Visible = True  # You can remove this line if you don't want the Excel application to be visible\n",
    "\n",
    "wb1 = xl.Workbooks.Open(Filename=path1)\n",
    "wb2 = xl.Workbooks.Open(Filename=path2)\n",
    "\n",
    "ws1 = wb1.Worksheets(\"Glossary\")\n",
    "ws2 = wb1.Worksheets(\"UserGuide_EWU-Dashboard\")\n",
    "ws1.Copy(Before=wb2.Worksheets(1))\n",
    "ws2.Copy(Before=wb2.Worksheets(1))\n",
    "\n",
    "wb2.Close(SaveChanges=True)\n",
    "#xl.Quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a77c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
